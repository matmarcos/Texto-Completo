\documentclass[12pt,a4paper]{amsart}
%\usepackage[brazil]{babel}
%\usepackage[portuguese]{babel}
\usepackage[T1]{fontenc}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage[hmargin={2cm},vmargin={2cm}]{geometry}
\usepackage{graphicx,color}

 
\usepackage{ifthen}                            % Caso tenha problemas ao usar UTF-8, experimente \usepackage{ucs}
\usepackage{calc}


\usepackage{amssymb,amsmath}   % simbolos matemáticos providos pela AMS
\usepackage{amsthm}						 % estilo dos teoremas
%\usepackage[dvipdfm]{graphicx} % para inclusão de figuras (png, jpg, gif, bmp)
\usepackage{fancyhdr}					 % personaliza cabeçalho e rodapé
\usepackage{color}             % para letras e caixas coloridas
%\usepackage{makeidx}           % índice remissivo
\usepackage{a4wide}            % correta formatação da página em A4
\usepackage{setspace}          % para a distância entre linhas
\usepackage[T1]{fontenc}
%\usepackage{egothic}
%\usepackage{yfonts}
\usepackage[all]{xy}
\usepackage{stackrel}	
\usepackage{geometry}
\usepackage{mathabx}

\parskip 5pt

\newcommand{\F}{\ensuremath{\mathbb{F}}}

\newcommand{\cqd}{\rule{2mm}{2mm}}
\newcommand{\prova}{\noindent \textbf{Proof: }}
\DeclareMathOperator{\mdc}{mdc} 
\DeclareMathOperator{\mmc}{mmc} 
\DeclareMathOperator{\supp}{supp} 


\newcommand{\der}[1]{{\sf Der}(#1)}
\newcommand{\gl}[1]{{\mathfrak g\mathfrak l}(#1)}
\newcommand{\ann}[2]{{\sf Ann}_{#1}(#2)}
\renewcommand{\ker}[1]{{\sf Ker}(#1)}
\newcommand{\im}[1]{{\sf Im}(#1)}

\newtheorem{teo}{Theorem}[section]
\newtheorem{cor}[teo]{Corollary}
\newtheorem{lem}[teo]{Lemma}
\newtheorem{obs}[teo]{Observation}


\newtheorem{prop}[teo]{Proposition}

\theoremstyle{definition}
\newtheorem{df}[teo]{Definition}
\newtheorem{ex}[teo]{Example}

\newcommand{\ad}[2]{{\sf ad}^{#1}_{#2}}
\newcommand{\ctwo}[2]{{\sf C}^2(#1,#2)}
\newcommand{\ztwo}[2]{{\sf Z}^2(#1,#2)}
\newcommand{\btwo}[2]{{\sf B}^2(#1,#2)}
\newcommand{\htwo}[2]{{\sf H}^2(#1,#2)}
\newcommand{\zone}[2]{{\sf Z}^1(#1,#2)}
\renewcommand{\hom}[2]{{\sf Hom}(#1,#2)}
\newcommand{\comp}[2]{{\sf Comp}(#1,#2)}
\newcommand{\sdsum}{\oright}
\newcommand{\ennd}[1]{{\sf End}(#1)}
\newcommand{\indu}[3]{{\sf Indu}(#1,#2,#3)}
\newcommand{\aut}[1]{{\sf Aut}(#1)}
\renewcommand{\bar}[1]{\overline{#1}}


\makeindex

\begin{document}

\title[non-singular derivations in prime characteristic]
      { DERIVATIONS OF LIE ALGEBRA EXTENSIONS AND NON-SINGULAR DERIVATIONS OF LIE ALGEBRAS IN PRIME CHARACTERISTIC}

\begin{titlepage}
\begin{center} 
{\large UNIVERSIDADE FEDERAL DE MINAS GERAIS}

{\large INSTITUTO DE CIÊNCIAS EXATAS}

{\large Departamento de Matemática}\\[2cm]
{\large \bf{Projeto de Tese de Doutorado}}\\[4cm]
{\bf \large DERIVATIONS OF LIE ALGEBRA EXTENSIONS AND NON-SINGULAR DERIVATIONS OF LIE ALGEBRAS IN PRIME CHARACTERISTIC}\\[4cm]
{\large \bf{Marcos Goulart Lima}}\\[0.7cm] 
{\large Orientador: Csaba Schneider }\\[4cm]
{\large Belo Horizonte}\\[0.2cm]
{\large Junho de 2016}
\end{center}


\end{titlepage}

\author{Marcos Goulart Lima }
\address{Departamento de Ci\^encias Exatas e Aplicadas \\
Instituto de Ci\^encias Exatas e Aplicadas \\
Universidade Federal de Ouro Preto\\
Rua 37, 115 \\
Jo\~ao Monlevade, MG,  Brazil\\
marcosgoulart@decea.ufop.br }
%\author{Csaba Schneider}
%\address{Departamento de Matem\'atica\\
%Instituto de Ci\^encias Exatas\\
%Universidade Federal de Minas Gerais\\
%Av.\ Ant\^onio Carlos 6627\\
%Belo Horizonte, MG, Brazil\\
%csaba@mat.ufmg.br\\
%www.mat.ufmg.br/$\sim$csaba}

\maketitle


\section{Introduction} 

Let $L$ be a Lie algebra and $d$ be a derivation of $L$. The derivation $d$ is non-singular if it is injective as linear transformation. We are interested in studying what information we can obtain about a Lie algebra if it has a nonsingular derivation. Jacobson's famous theorem \cite{Jacobson} states that a finite-dimensional Lie algebra over a field of characteristic zero that admits a non-singular derivation must be nilpotent. It is well-known that this theorem is not valid when the characteristic is non-zero. Non-nilpotent and solvable examples were constructed by Shalev~\cite{Shalev} and Mattarei~\cite{Mattarei}, whereas the simple Lie algebras with non-singular derivations were classified by Benkart and her collaborators in~\cite{Benkart}. A significant application of Lie algebras with non-singular derivation in characteristic $p$ was presented by Shalev \cite{Shalev2}. In his proof of the coclass conjectures of Leddham-Green and Newman for pro-$p$ groups, Shalev uses the fact that finite-dimensional Lie algebras over a field of characteristic $p>0$ with non-singular derivation $d$ such that $d^{p-1}=1$, must be nilpotent. 
 
Despite the existing examples, little is known about non-nilpotent Lie algebras with non-singular derivations. In this project we propose to explore the structure of solvable, non-nilpotent Lie algebras with non-singular derivations. In order to study these algebras we develop a theory of derivations of Lie algebra extensions. We adopt the concept of a compatible pair of automorphisms introduced in~\cite{Eick} for derivations of Lie algebras. 

Let $K$ and $I$ be Lie algebras such that $K$ acts on $I$, then we can define the subalgebra $\comp K I$ of {\em compatible pairs} of $\der K \oplus \der I$ as the set of derivations of $\der K \oplus \der I$ that are derivations of the semi-direct sum $K \sdsum I$. Formally,
$$\comp KI=\{\alpha+\beta\in\gl K\oplus\gl I\mid
  \alpha+\beta\in\der{K\sdsum I}\}.$$ The algebra $\der K$ carries information about the multiplicative structure of $K$. Analogously, the algebra $\comp K I$ carries information about the action of $K$ on $I$. In Section \ref{secJacobson} we present an example of this by exploring the proof of Jacobson's Theorem and we prove a version for Lie algebra representations over a field of characteristic  $p>0$. 

\textbf{Theorem \ref{1.8}} \textit{ Let $K$ and $I$ be finite dimensional Lie algebras over a field of characteristic $p$ where $p \geq 0$ such that $K$ is nilpotent. Suppose that $K$ act on $I$ by representation $\psi:K \to \der I$. Let $(\alpha, \beta) \in \comp K I$ such that $\alpha$ has no eigenvalue 0. If either $p=0$ or $p>0$ and $\dim I < p $ then $Tr(\psi^n(k))=0$, for all $k \in K$ and  $n>0$. In these two cases, $\psi(k)$ is nilpotent for all $k \in K$.}

We also adapt an algorithm presented by Bettina Eick \cite{Eick} for calculating the automorphism group of solvable Lie algebras. A key step in the algorithm is the following. Let $L$ be a Lie algebra and $I$ an abelian ideal of $L$ such that $I$ is invariant under $\aut L$. Then there exists a homomorphism $\phi: \aut L \to \aut {L/I} \times \aut I$ induced by the actions of $\aut L$ on $L/I$ and $I$. The image of $\phi$ can be calculated using $\aut{L/I}$, while $\ker \phi $ is equal to $\zone K I$. Then the group $\aut L$ can be obtained applying the first isomorphism theorem to $\phi$. It is possible to use this process to derivations.

We can define a Lie algebra homomorphism similar to $\psi$ in the previous paragraph. Let $L$ be a Lie algebra and $I\unlhd L$ an ideal such that $I$ is invariant under $\der L$. Then if $d \in \der L$, $d$ induces derivations $\alpha$ and $\beta$ of $L/I$ and $I$, respectively. Hence we obtain a Lie algebra homomorphism $$\psi:\der L \to \der {L/I} \oplus \der I.$$

Let $K$ be a Lie algebra and $I$ be a $K$-module. Let $\ztwo K I $ be the vector space of cocycles and $\comp K I$ the Lie algebra of compatible pairs. Let $(\alpha, \beta) \in \comp KI$ and $\vartheta \in \ztwo KI$. Define an action of $\comp K I$ on $\ztwo K I $ by 
\begin{center}
$(\alpha,\beta)\cdot \vartheta(h,k)=\beta(\vartheta(h,k))-\vartheta(\alpha(h),k)-\vartheta(h,\alpha(k)), \quad \mbox{ for all } h,k \in K.$
\end{center}
The elements of the annihilator of $\vartheta$ under this action will be called {\em induced pairs} and we denote the set of induced pairs by $\indu K I \vartheta$. Let $\vartheta \in \ztwo K I$ a cocycle and $K_\vartheta$ be the Lie algebra extension obtained from $K$ by $\vartheta$. Then we can lift the derivation of $\indu K I \vartheta$ to $\der{K_\vartheta}$. Thus we obtained the following theorem.

\textbf{Theorem  \ref{DerExt}} \textit{ Let $K$ be a Lie algebra and $I$ a $K$-module. Let $\vartheta \in \htwo KI$ and suppose  that $I$, as an ideal of $K_\vartheta$, is invariant under derivations of $K_\vartheta$. Let $\phi:\der {K_\vartheta} \to \der K \oplus \der I$ the natural homomorphism. Then:
  \begin{enumerate}
 \item $\im \phi=  \indu K I \vartheta$
  \item $\ker \phi \cong  \zone KI.$
  \end{enumerate}}
  
The details of this construction can be seen in Section \ref{extensions}. There is a significant difference between the application of this approach to automorphisms and to derivations: calculating the automorphism groups of Lie algebras is usually a difficult task that may involve a large orbit-stabilizer calculation, while calculating the algebra $\der {K_\vartheta}$ can be done by solving a system of linear equations. Thus, to understand the importance of Theorem \ref{DerExt} we must discover what additional information of $\der {K_\vartheta}$ we are able to obtain through information concerning the algebras $\der{K}$ and $\der I$.
  
 In order facilitate the reading of the text and the references, we added a section with results on the primary decomposition of vector spaces in relation to subalgebras of linear operators and a brief description of the main articles used. 
  
 This text is organized as follows: Section 2 is dedicated to literature review. In Section 3, we present compatible pairs and the lifting process of derivations of a Lie algebra $K$ to the Lie algebras $K_{\vartheta}$ such that $\vartheta$ is a cocycle. We end this section by applying the compatible pairs to Jacobson's Theorem. Section 4 is composed of some examples and conjectures about modular solvable non-nilpotent Lie algebras with non-singular derivations.
 
\section{Non-singular derivations: known results} This section is composed by description of a decomposition of a Lie algebra $L$ relative to a subalgebra $K$ of $\gl L$ and its application in Jacobson's Theorem. Next, we have the calculations presented in Shalev's article \cite{Shalev} about conditions on the order of derivation which guarantee nilpotency of a Lie algebra. The section ends with Mattarei's Theorem that relates the order of non-singular derivations of solvable modular Lie algebras to roots of certain types of polynomials.


\subsection{Basic concepts} 
The symbol `$\oplus$' will be used to denote the direct 
sum of algebras,
while  the
direct sum of vector spaces will be denoted by `$\dotplus$'.

Let $V$ be a finite-dimensional vector space over a field $\F$ and $a \in \ennd V$. Let $p \in \F[X]$ be a univariate polynomial and define $$V_0(p(a))=\{v \in V \mid  \mbox{ there is an } m>0  \mbox{ such that } p(a)^mv=0\}.$$ 
 $V_0(p(a))$ is a vector subspace of $V$ invariant under $a$. Now let $A$ be the associative sualgebra of $\ennd V$ with 1 generated by $a$. Let  $p_a$ be the minimum polynomial of $a$ and suppose that  $$p_a=p_1^{k_1} \cdots p_r^{k_r}$$ is the factorization of $p_a$ into irreducible factors, such that $p_i$ has leading coefficient 1 and $p_i \neq p_j$ for $1 \leq i, j \leq r$. Then $V$ decomposes as a direct sum of subspaces $$V=V_0(p_1(a)) \dotplus \cdots \dotplus V_0(p_r(a)),$$ each space $V_0(p_i(a))$ being invariant under $A$. Furthermore, the minimum polynomial of the restriction of $a$ to $V_0(p_i(a))$ is $p_i^{k_i}$. A proof of this result can be found in \cite{deGraaf} Lemma A.2.2.   
 
We can generalize this decomposition to subalgebras of $\gl V$ generated by more than one element. Let $K$ be a subalgebra of $\gl V$. A decomposition $V = V_1 \dotplus \cdots \dotplus V_s$ of $V$ into $K$-modules $V_i$ is said to be \textit{primary} if the minimum polynomial of the restriction of $a$ to $V_i$ is a power of an irreducible polynomial for all $a \in K$ and $1 \leq i \leq s$. The subspaces $V_i$ are called primary components. If for any two components $V_i$ and $V_j$ $(i \neq j)$, there is an $x \in K$ such that the minimum polynomials of the restrictions of $x$ to $V_i$ and $V_j$ are powers of different irreducible polynomial, then the decomposition is called \textit{collected}. In general $V$ will not have a primary (or primary collected) decomposition into $K$-modules but such a decomposition is guaranteed to exist if the base field of $V$ is algebraically closed and $K \leq \gl V$ is nilpotent. 

\begin{prop}[\cite{deGraaf}, Theorem 3.1.10] Let $V$ be finite-dimensional vector space. Let $K \leq \gl V$ be a nilpotent subalgebra. Then $V$ has a unique collected primary decomposition relative to $K$
\end{prop}

If the vector space $V$ has a collected primary decomposition $V = V_1 \dotplus \cdots \dotplus V_s$ then we can characterize the components $V_i$. For $x \in K$ and $1 \leq i \leq s$ define $p_{x,i}$ to be the irreducible polynomial such that the minimum polynomial of $x$ restricted to $V_i$ is a power of $p_{x,i}$. Then we obtain the equality  $$V_i=\{v \in V \mid  \mbox{ for all } x \in K \mbox{ there is an } m>0  \mbox{ such that }  p_{x,i}(x)^mv=0\}.$$ 
It is worth noting that if the base field of $V$ is algebraically closed, then all irreducible polynomials are of the form $p(X)= (X - \lambda)$, for some $\lambda \in \F$, and hence $p_{x,i}=( X - \lambda_i(x)), \lambda_i \in \F^*$. Further, in this case, primary components are of the form $$V_i=\{v \in V \mid  \mbox{ for all } x \in K \mbox{ there is an } m>0  \mbox{ such that }  (x - \lambda_i(x)I)^mv=0\},$$ with $\lambda_i \in K^*$. Its natural to give a name for this case. Let $V$ be a finite-dimensional vector space over a field $\F$ and $K \leq \gl V $ a subalgebra. Let $\lambda \in K^*$. Then $$V_{\lambda}=\{v \in V \mid  \mbox{ for all } x \in K \mbox{ there is an } m>0  \mbox{ such that }  (x - \lambda(x).I)^mv=0\}.$$ If $V_\lambda \neq 0$ then $V_\lambda$ is called a \textit{generalized eigenspace} of $V$ associated to the \textit{generalized eigenvalue} $\lambda \in K^*$.

Now we consider a Lie algebra $L$ and a nilpotent subalgebra $K \leq \der L $. Then the decomposition to generalized eigenspaces of $D$ can provide us some  information of the multiplicative structure of $L$. 

\begin{prop}[\cite{JacobsonBook}, Proposition 5 of Chapter III]{\label{1.01}} 
 Let $L$ be a Lie algebra over an algebraically closed field. Let $K$ be a  subalgebra of $\der L$. If $\lambda,\mu:K \to \F^*$ are generalized eigenvalues of $K$  then $[L_\lambda,L_{\mu}] \subseteq L_{\lambda+\mu}$ if $\lambda+\mu$ is a  generalized eigenvalue of $K$. Otherwise $[L_{\mu}, L_{\lambda}]=0$.
\end{prop}

Following we present some general results about Lie algebras that will be used in the this text.

\begin{prop} {\label{adnilp}}Let $L$ be a Lie algebra, let $I$ be an ideal of $L$ such that $L/I$ is nilpotent and such that $\ad{I}{x}: I \to I$ is nilpotent for all $x \in L$. Then $L$ is nilpotent.
\end{prop}
\begin{proof} As $L/I$ is nilpotent then for each $x \in L$, $(\ad{}{x+I})^n$ is a nilpotent endomorphism in $\ennd {L/I}$, i.e., there is $n>0$ such that $(\ad{}{x})^n(a) \in I$, for all $x \in L, a \in I$. On the other hand, $\ad{I}{x}$ is nilpotent, so we have a $m$ such that $(\ad{I}{x})^m(\ad{}{x})^n=0$, i.e., $(\ad{}{x})^{m+n}=0$. So $\ad{}{x}$ is a nilpotent endomorphism in $  \gl L$. By Engel's Theorem, $L$ is nilpotent.
\end{proof}

\begin{teo}[\cite{Humphreys}, Theorem 4.1]{\label{Lielemma}} Let $L$ be a solvable subalgebra of $\gl V$, $V$ finite-dimensional. If $V\neq 0$, then $V$ contains a common eigenvector for all the endomorphism in $L$.
\end{teo}
  
\begin{teo}[\cite{Humphreys}, Corollary A of Theorem 4.1]{\label{Lie0}}(Lie) Let $L$ be a finite-dimensional solvable Lie algebra over an algebraically closed field $\F$ of characteristic 0. Let $\psi:L \to \gl V$ be a finite-dimensional representation of $L$. Then there is a basis of $V$ relative to which the matrix of all $\psi(x)$ for all $x \in L$ are all upper triangular. 
\end{teo}
 The Theorems \ref{Lielemma} and \ref{Lie0} still valid in characteristic $p>0$ if $\dim V<p$. The proof of Theorem \ref{Lielemma} in prime characteristic goes through as in the Humphreys' book except for the last sentence. In the book's version, we have $n\lambda([x, y]) = 0$ and conclude $\lambda([x, y]) = 0$ because the characteristic of $\F$ is 0. In this case, since $ p > \dim V = n$, we can still make the same conclusion since $n$ will not be a zero divisor. The proof of Theorem \ref{Lie0} goes through exactly as in the book. For future reference in the text we will report a version of the Lie's Theorem in positive characteristic.

\begin{teo}{\label{Lie}} Let $L$ be a finite-dimensional solvable Lie algebra over an algebraically closed field $\F$ of characteristic $p>0$. Let $V$ be a finite-dimensional vector space of dimension $n<p$. Let $\psi:L \to \gl V$ be a finite-dimensional representation of $L$. Then there is a basis of $V$ relative to which the matrix of all $\psi(x)$ for all $x \in L$ are all upper triangular. 
\end{teo}

\subsection{Jacobson's Theorem}

 In the article \textit{A note on automorphism and derivations of Lie algebras} \cite{Jacobson}, Jacobson used a variation of Engel's Theorem for weakly closed sets to get sufficient conditions for a Lie algebra to be nilpotent. We recommend the reading of Sections 1 and 2 of Chapter 2 of Jacobson's book \cite{JacobsonBook} as reference for examples and proofs.
 
 Suppose that $K$ and $I$ are Lie algebras and $\psi:K\rightarrow\der I$
is a given Lie algebra homomorphism.
Then we say that  $K$ {\em acts} on $I$ or that $I$ is a {\em $K$-module}.
In this case, the image $\psi(k)(a)$ of $a\in I$ under
$k\in K$ will be written
simply as $[k,a]$.
If $I$ is an ideal of a Lie algebra $K$, then $K$ acts on $I$. If 
$k\in K$, then the image of $k$ under this action will be denoted by $\ad Ik$ or
simply by $\ad {}k$ when the domain of the representation is clear from 
the context. Thus, for $a\in I$ and for
$k\in K$, $\ad Ik(a)=\ad{}k(a)=[k,a]$.  The homomorphism
$K\rightarrow \der I$ that takes $k\mapsto\ad Ik$, 
will be denoted by $\ad I{}$. 

\begin{ex}{\label{adjrepex}} Let $L$ be a Lie algebra with an abelian ideal $I$ and
  set $K=L/I$.
  Define the Lie algebra representation $\ad{I}{}:K \to \der I$
  by $\ad{I}{x+I}(a)=[x,a]$ for
  all $x\in L$ and $a \in I$. This is well defined, since
  $I$ is abelian. Then $I$ is a $K$-module. In this case,
  we say that the action is {\em induced by the
    adjoint representation}.
\end{ex}

Let $A$ be an associative algebra with $1$ over a field $\F$. A subset $S$ of $A$ is called \textit{weakly closed} if for every ordered pair $(a, b)\in S \times S,$ there is an element $\gamma(a,b) \in \F$ such that $ ab+ \gamma (a, b) b a \in S$. If $S$ is a subset of an Lie or associative algebra $X$, then $\langle S \rangle$ denotes the Lie or associative, respectively, subalgebra of $X$ generated by $S$. In the case of associative algebras we assume that $1 \in \langle S \rangle$. This notation may cause confusion when $X$ is an associative and Lie algebra in the same time, in such cases we will indicate clearly if $\langle S \rangle$ denotes associative or Lie subalgebra. 

\begin{prop}[\cite{JacobsonBook}, Theorem 1 of Chapter II]{\label{1.02}} Let $V$ be a finite-dimensional vector space over a field $\F$. Let $S \subseteq \ennd V$ be a weakly closed subset such that every $s \in S$ is associative nilpotent, that is, $s^k=0$, for some positive integer $k$. Then the associative subalgebra $\langle S \rangle \leq \ennd V$ is nilpotent. 
\end{prop}

 With this result we can prove Jacobson's Theorem.
 
\begin{teo}[\cite{Jacobson}, Theorem 3]{ \label{Jacobsontheo}} Let $L$ be a finite-dimensional Lie algebra over a field of characteristic 0 and suppose that there exists a subalgebra $D$ of the algebra of derivations of $L$ such that
\begin{enumerate}
 \item $D$ is nilpotent;
 \item if there is $c \in L$ such that $d(c)=0$ for all $d \in D$ then $c=0$.
\end{enumerate} Then $L$ is nilpotent. 
\end{teo}
\begin{proof} Let $\bar{\F}$ be the algebraic closure of the base field. We can  extend all derivations of $L$ to $\bar{L}=L \otimes \bar{\F}$. If we prove that $\bar{L}$ is nilpotent then $L$ is nilpotent. So we will assume that $\F$ is algebraically closed. In this case the extension of $D$ is nilpotent and without 0 as common eigenvalue, i.e. if there is $c \in L$ such that $d(c)=0$ for all $d \in D$ then $c=0$. Let $L = L_{\gamma_1} \dotplus \cdots \dotplus L_{\gamma_t}$ be the decomposition of $L$ into generalized eigenspaces of $D$. By Proposition \ref{1.01} we have $[L_{\gamma_i},L_{\gamma_j}] \subseteq L_{\gamma_i+\gamma_j}$ if $\gamma_i+\gamma_j$ is a eigenvalue of $D$ and $[L_{\gamma_i},L_{\gamma_j}]=0$ otherwise. For a subset $Y \subseteq L$, we let $\ad {} {Y}$ denote the set of adjoint mappings induced by elements of $Y$. Then the inclusion just noted shows that the set $ S= \bigcup \ad {}{L_{\gamma_j}}$ is a weakly closed set of linear transformations. Let $a \in L_{\gamma_j}$ and $b \in L_{\gamma_i}$. Then $(\ad{}{a})^s(b) \in L_{\gamma_i+s \gamma_j}$, for all $s \geq 0$.(*) 

The generalized eigenvalue $\gamma_j \neq 0$ and $\F$ has characteristic 0 then $\gamma_i+s \gamma_j$, for $s>0$, are pairwise distinct. Then for some $r$ large enough $(\gamma_i+r\gamma_j)$ is not an eigenvalue and $\ad{}{a}(b)=0$. Follow that $\ad{}{a}$ is nilpotent linear transformation. Thus every element of $S$ is nilpotent. By Proposition \ref{1.02} the associative subalgebra $\langle S \rangle  \leq \ennd V$ is nilpotent. Observe that the Lie subalgebra $\langle S \rangle$ is subset of the associative subalgebra $\langle S \rangle$, then $\langle S \rangle$   is nilpotent as Lie subalgebra. But $\langle S \rangle =\ad{}{L}$ implies that $L$ is a nilpotent Lie algebra.   
\end{proof}

A review of the proof of Theorem \ref{Jacobsontheo} shows that the hypothesis of zero characteristic is essential to prove that every element in a homogeneous component is nilpotent. As the following examples shows, Theorem \ref{Jacobsontheo} fails to hold in characteristic $p>0$.  

\begin{ex} Let $\F$ be the field of $2^m$ elements and $L$ be the vector space over $\F$ such that $$L= \langle x_\alpha \mid \alpha \in \F, \alpha \neq 0\rangle$$ with a basis labeled by nonzero elements of the field $\F$ and with multiplication $[x_\alpha, x_\beta]=(\beta-\alpha)x_{\alpha+\beta}$. Then $L$ is a simple Lie algebra and the map $d \in \ennd L$ given by $d(e_\alpha)=\alpha e_\alpha$ is a non-singular derivation. The calculations of this example and a systematic investigation of simple Lie algebras with nonsingular derivations can be found in \cite{Benkart}.
\end{ex}

\begin{ex}
 Let $V$ be a vector space over a field $\F$ of characteristic $p>0$. Let $B=\{a_1,a_2, \cdots, a_p\}$ be a basis of $V$. Define the linear map $x \in \gl V$ by $$x(a_i)=a_{i+1 \mod p}, 1 \leq i \leq 0.$$ Let $K$ be the abelian Lie algebra generated by $\{x, x^2, \cdots, x^{p-1}\}$. Then $V$ can be considered as $K$-module with the standard action of $\gl V$ on $V$. Let $L$ be the semi-direct sum $L=K \sdsum V$ then $L$ is an Solvable non-nilpotent Lie algebra of derived length 2. Let $\lambda,\delta \in \F$ both non-zero and $\lambda \neq s \delta $, for all $s \in \F_p$. The linear map $d:L \to L$ defined by
  $$d: \left\lbrace\begin{array}{lc}
 x^j \mapsto j\lambda x^j, &1 \leq j \leq p-1; \\
 a_i \mapsto (\delta +(i-1)\lambda)a_i, & 1 \leq i \leq p,
\end{array} \right.$$ 
is a non-singular derivation of $L$.
\end{ex} 
  
  For Lie algebras over fields of characteristic $p> 3$ we could not find an example of derived length greater than 3 but in characteristic 2 we have the following example.
      
\begin{ex} Let $L$ be a vector space of dimension 6 over $\F_4$. Let $\lambda \in \F_4$ such that $\lambda^2=\lambda+1$ and $\{a_1,a_2,a_3,a_4,a_5,a_6\}$ a basis of $L$ over $\F_4$. Define the products

\begin{center}
\begin{tabular}{llll}
$[a_1,a_3]=\lambda a_5+a_6,$ & $[a_1,a_4]=\lambda a_6,$ & $[a_1,a_5]=\lambda^2 a_3+a_4,$  & $[a_3,a_5]=\lambda a_2,$ \\
$[a_1,a_6]=\lambda^2 a_4 ,$  & $[a_2,a_3]=\lambda a_6,$ & and $[a_2,a_5]=\lambda^2 a_4.$ & \\
\end{tabular}
\end{center}

 $L$ is a solvable non-nilpotent Lie algebra of derived length 3. The linear map $d: L \to L$ defined by 
   $$d: \left\lbrace\begin{array}{ccc}
a_1 \mapsto a_1 & a_3 \mapsto \lambda a_3 & a_5 \mapsto \lambda^2 a_5 \\
a_2 \mapsto a_2 & a_4 \mapsto \lambda a_4 & a_6 \mapsto \lambda^2 a_6
\end{array} \right.$$

 is a non-singular derivation of $L$.
\end{ex}  

 Another question is whether the converse of Jacobson's Theorem is true, that is, is it true that all finite-dimensional nilpotent Lie algebras admit non-singular derivation. By Dixmier and Lister \cite{Dixmier}, there are nilpotent Lie algebras admitting only nilpotent derivations. Bellow we present Dixmier and Lister example of such an algebra.
 
 \begin{ex} Let $\F$ be a field of characteristic 0 and $L = \langle x_1, x_2, \cdots, x_8 \rangle$ be a Lie algebra over $\F$  with dimension 8 and multiplication table 

$[e_1,e_2]=e_5 \quad [e_1,e_3]=e_6  \quad[e_1,e_4]=e_7  \quad [e_1,e_5]=-e_8  \quad [e_2,e_3]=e_8 \quad [e_2,e_4]=e_6 $

$ [e_2,e_6]=-e_7 \quad [e_3,e_4]=-e_5 \quad [e_3,e_5]=-e_7 \quad [e_4,e_6]=-e_8 \quad  [e_i,e_j]=-[e_j,e_i].$

Moreover, $[e_i,e_j]=0$ if it is not in table above. Then $L$ is nilpotent with $L^3 \neq 0$,  $L^4=0$ and every derivation of $L$ is nilpotent.
\end{ex}


\subsection{Jacobson's Theorem in characteristic $p>0$}
 As the examples above shows, Jacobson's Theorem is in general not true in characteristic $p>0$. However, we have the follow weaker result.

\begin{teo}{\label{JacoModp}} Let $L$ be a Lie algebra over a field of characteristic $p>0$ and suppose that there exists a subalgebra $D \leq \der L$ such that 
\begin{enumerate}
\item $D$ is nilpotent;
\item if there is $c \in L$ such that $d(c)=0$ for all $d \in D$ then $c=0$.
\end{enumerate} If $D$ has at most $p-1$ generalized eigenvalues then $L$ is nilpotent. 
\end{teo}
\begin{proof} The proof of this theorem is identical to proof of Theorem $\ref{Jacobsontheo}$ up to point marked by (*). The generalized eigenvalue $\gamma_j \neq 0$ then the set $\{\gamma_i, \gamma_i+\gamma_j, \cdots , \gamma_i+(p-1)\gamma_j\}$ has $p$ distinct elements. As $D$ has at most $p-1$ generalized eigenvalues then for some $r$, $0 < r \leq p-1$, $(\gamma_i+r\gamma_j)$ is not an eigenvalue. Follow that $\ad{}{a}$ is nilpotent linear transformation, for every $a \in L_{\gamma_i}$. Thus every element of $S$ is nilpotent. By Proposition \ref{1.02} the associative subalgebra $\langle S \rangle  \leq \ennd V$ is nilpotent and hence $\ad{}{L}$ is nilpotent. Therefore $L$ is a nilpotent Lie algebra.
\end{proof}

\subsection{The orders of non-singular derivations} An interesting approach by  Shalev in article \cite{Shalev} is to study the order of nonsingular derivations, establishing conditions for a Lie algebra over a field of characteristic $p$ with non-singular derivations to be nilpotent. More precisely, Shalev studied the set of orders of nonsingular derivations of non-nilpotent Lie algebras of characteristic $p>0$. Later, Mattarei in \cite{Mattarei} showed that this set of numbers corresponds to the set of solutions of some polynomial equation over a field of characteristic $p$. Below we present some results of these articles.

Let $L$ be a Lie algebra over an algebraically closed field of characteristic $p$. We can characterize the matrix of a non-singular derivation of $L$. We need a result for derivations in Lie algebras over a field of characteristic $p>0$. 

\begin{lem}{\label{leib}} Let $L$ be a Lie algebra over a field $\F$ of characteristic $p>0$. If $d \in \der L$ then $d^{p^m} \in \der L,$ for all $m \geq 1.$
\end{lem}
\begin{proof} If we prove this result for $m=1$ then the general case when $m \geq 1$ will follow by induction. Let us hence prove the statement only for $m=1$. Let $d \in \der L$ and $x,y \in L.$ First we prove the Leibniz's formula by induction:  $$d^n([x,y])=\sum_{k=0}^n \binom{n}{k}[d^k(x),d^{n-k}(y)], \mbox{ for all }  n>0.$$
The case $n=1$ follow from derivation's definition. Suppose that Leibniz's formula is valid for $n$. Then
\begin{equation}{\label{leib1}}
 d^n([x,y]) =  \sum_{k=0}^n \binom{n}{k}[d^k(x),d^{n-k}(y)].
\end{equation}
Calculating $d$ in both sides of equation (\ref{leib1}) we have
\begin{equation}\label{leib2}
d^{n+1}([x,y]) = \sum_{k=0}^n \binom{n}{k}[d^{k+1}(x),d^{n-k}(y)]+\sum_{k=0}^n \binom{n}{k}[d^{k}(x),d^{n-k+1}(y)] .
\end{equation}
 Rearranging the index, the right side of equation (\ref{leib2}) can be write as 
\begin{equation*}
[d^{n+1}(x),y]+\sum_{k=1}^{n} \left(\binom{n}{k-1}+\binom{n}{k}\right)[d^{k}(x),d^{n+1-k}(y)]+[x,d^{n+1}(y)].
\end{equation*}
As $\binom{n}{k-1}+\binom{n}{k}=\binom{n+1}{k}$ then 
 $$d^{n+1}([x,y])=\sum_{k=0}^{n+1} \binom{n+1}{k}[d^k(x),d^{n+1-k}(y)].$$
 Then by induction Leibniz's formula is proved. As the field $\F$ has characteristic $p>0$ then setting $n=p^m$ the Leibniz's formula is reduced to $$d^{p^m}([x,y])=[d^{p^m}(x),y]+[x,d^{p^m}(y)].$$
\end{proof}

\begin{prop}{\label{NonSDiag}}  Let $V$ be a finite-dimensional vector space over an algebraically closed field of characteristic $p>0$ and $f \in \ennd V$ non-singular with order $r$ coprime to $p$. Then $f$ is diagonalizable.
\end{prop}

\begin{proof} Let $A$ be the matrix of the endomorphism $f$ in Jordan normal form and write $A=S+N$ such that $S$ is diagonal, $N$ is nilpotent upper triangular and $S,N$ commute. Denote by $M_{ij}$ the element of a matrix $M$ of the $i^{th}$ line and the $j^{th}$ column. It follows that \begin{itemize}
\item  If  $S_{ii} = \lambda_i$ then $(S^k)_{ii}=\lambda_i^k,$ for  all $k>0$;
\item $N^k_{i(i+j)}=0,$ for all $0 \leq j < k$.
\end{itemize}
As the order of $A$ is $r$ we have $A^r=Id$. Then 
$$I=A^r=(S+N)^r=S^r+\binom{r}{1} S^{r-1}N+ \binom{r}{2}S^{r-2}N^2+\cdots + \binom{r}{r-1}SN^{r-1}+N^r.$$


The identity matrix on the left-hand side of the last equation is diagonal, while the summands, with the exception of the first summand, on the right-hand side are nilpotent. Further, if $N \neq 0$, then the second summand $rS^{r-1}$N in non-zero, and it is the only summand that contains a non-zero entry in a positions $(i,i+1)$ with $i > 0$. However, this implies that if $N \neq 0$, then $A^r$ must contain a non-zero entry in a position $(i,i+1)$, which is a contradiction, as $A^r=I$. Hence $N=0$ as claimed. Then $f$ is diagonalizable.
\end{proof}

Let $L$ be a Lie algebra over the field $\F$ of characteristic $p>0$ such that $L$ has a non-singular derivation $d$. Let $r$ be the order of $d$ such that $r=sp^t$, with $\gcd (s,p)=1$. Then by Lemma \ref{leib} $d^{p^t}$ is a derivation whose order is prime to $p$ and, by Proposition \ref{NonSDiag}, $d^{p^t}$ is diagonalizable. So if $L$ is a Lie algebra over an algebraically closed field $\F$ of characteristic $p>0$ with non-singular derivation then $L$ has a diagonalizable derivation $d$ without eigenvalue 0.
 
 \begin{prop}[\cite{Shalev}, Lemma 2.2 ]{\label{Shalevlem}} Let $L$ be a finite-dimensional Lie algebra in characteristic $p>0$ which admits a non-singular derivation $d$ whose order $n$ is coprime to $p$. Suppose that $L$ is not nilpotent. Then there exist $\lambda \in \bar{\F}_p$ such that $(\lambda+ \delta)^n=1$ for all $\delta \in \F_p$.
\end{prop}

\begin{proof} Let $\bar{\F}$ be a algebraic closure of $\F$ and $R=\{\alpha \in \bar{\F}_p  \mid \alpha^n=1\}$. If $R$ is not contained in base field of $L$ then we consider $d$ for the extension $L \otimes \bar{\F}$. By Proposition \ref{NonSDiag}, $d$ is diagonalizable. Let $L=L_{\lambda1} \dotplus \cdots \dotplus L_{\lambda_r}$ the decomposition of $L$ to eigenspaces of $d$. The set $S=\bigcup \ad{}{L_{\lambda_j}}$ is weakly closed with $\gamma(\ad{}{a},\ad{}{b})=-1$ for all $a \in L_{\lambda_i}, b \in L_{\lambda_j}$. If each $\ad{}{a}$ is nilpotent then the associative subalgebra $\langle S \rangle \leq \gl L$ is nilpotent by Proposition \ref{1.02}. Hence $\ad{}{L}$ is a nilpotent Lie algebra and $L$ is nilpotent. As $L$ is non-nilpotent by hypothesis then there is $a \in L_{\lambda_j}$ and $b \in L_{\lambda_i}$ such that $(\ad{}{a})^n(b) \neq 0$, $1 \leq n \leq p$. However this implies $(\lambda_i+ \delta \lambda_j)$ are eigenvalues of $d$ for  $1 \leq \delta \leq p$. Since $|d|=n$ each eigenvalue of $d$ has order $n$. Thus $(\lambda_i+\delta \lambda_j)^n=1,$ for all $\delta \in \F_p$. As $\lambda_j$ is an eigenvalue of $d$, $\lambda_j^n=\lambda_j^{-n}=1$. Thus $1=(\lambda_i+\delta \lambda_j)^n\lambda^{-n}=(\lambda_i\lambda_j^{-1}+ \delta)^n$. Therefore setting $\lambda=\lambda_i \lambda_j^{-1}$, $(\lambda + \delta)^n =1$ for all $\delta \in \F_p$.
\end{proof}  

Usying the same notation as in the proof of Proposition \ref{Shalevlem} and observing that the set $R$ contains precisely the $n$-th roots of unity in $\bar{\F}$, we write $x^n-1=\prod_{\alpha \in R}(x - \alpha)$. As for all $\delta \in \F_p$, $\lambda+ \delta \in R$, $\prod_{\delta \in \F_p}(x-\lambda - \delta)$ divides $x^n-1$. But $$\prod_{\delta \in \F_p}(x-\lambda - \delta)=(x-\lambda)^p-(x-\lambda)=x^p-x-c,$$ where $c=\lambda^p-\lambda$. The first equation of last display can be seen by observing that the elements $\lambda+\delta$ with $\delta \in \F_p$ are exacty the $p$ roots of the polynomial $(x-\lambda)^p-(x-\lambda)$. Let $g(x)=x^p-x-c$. Then $g(x)$ divides $x^n-1$, which implies that $x^n$ is congruent to 1 modulo $g(x)$. In this case, Lemma 2.4 of \cite{Shalev} shows that $n \geq p^2-1$. Now we can prove the theorem.

\begin{teo}[\cite{Shalev}, Theorem 1.1] Let $L$ be a finite dimensional Lie algebra in characteristic $p>0$ which admits non-singular derivation of order $n$. Write $n=p^sm$ where $m$ is coprime to $p$. Suppose $m<p^2-1$. Then $L$ is nilpotent.   
\end{teo}

\begin{proof} The derivation $d^{p^s}$ has order $m$. Suppose that $L$ is not nilpotent. Then by the comment above we have $m \geq p^2-1$.
\end{proof}

  Mattarei in \cite{Mattarei} presented an example of non-nilpotent solvable modular Lie algebra. 
  
\begin{ex}{\label{mattareiex}} Let $\alpha, \beta \in \bar{\F}_p$ with $\alpha \beta^{-1} \notin \F_p $. Let $M$ be a $p$-dimensional vector space over $\bar{\F}_p$ with basis $e_1, \cdots, e_p$, and let $E,F$ be the linear transformations of $M$ defined by $E(e_i)=e_{i+1}$(indices modulo $p$), and $F(e_i)=(\alpha +i \beta)e_i$. The transformations $E$ and $F$ span a two-dimensional solvable Lie algebra, which admits $M$ as a left module. Let $L$ be the semidirect sum of $\lbrace E \rbrace$ and $M$ with respect to this action. Then $F$ acts on $L$ as a non-singular derivation, with eigenvalues $\beta$ on $\lbrace E \rbrace$, and $\alpha + \lambda \beta$ for $\lambda \in \F_p$ on $M$.    
\end{ex}  

 The next result links the orders non-singular derivations of Lie algebras of characteristic $p$ to some polynomial equations.

\begin{prop} Let $p$ be a prime number and let $n$ be a positive integer, prime to $p$. The following statements are equivalent:
\begin{enumerate}
\item there exists a non-nilpotent Lie algebra of characteristic $p$ with a non-singular derivations of order n;
\item there exists an element $\alpha \in \bar{\F}_p$ such that $(\alpha + \lambda)^n=1$ for all $\lambda \in \F_p$
\item there exist an element $c \in \bar{\F}_p^*$ such that $x^p-x-c$ divides $x^n-1$ as elements of the polynomial ring $\bar{\F}_p[x]$.
\end{enumerate}
\end{prop}

Mattarei in \cite{Mattarei} defines the set $N_p$ of the possible orders of non-singular derivations of non-nilpotent Lie algebras of characteristic $p$ and determine all elements of $N_p$ which are smaller than $p^3$, for $p>3$.   

\subsection{Objectives of the project} 

In this section we will present some questions about solvable non-nilpotent modular Lie algebras $L$ with a non-singular derivation $d$. This questions are based in the examples and results showed in the previous sections. These issues will serve as a reference for further work.

\textbf{Problem 1.} Is there a solvable, non-nilpotent Lie algebra over a field of characteristic $p\geq3$ with non-singular derivation and derived length greater than 2? 

Suppose that the answer to Problem 1 is yes and let $L$ be such Lie algebra. Let $I=L^{(2)}$ and $K=L/I$. As $L^{(3)}=0$ then $I$ is abelian and so $K$ acts on $I$ by adjoint representation. In this case, $K$ is a solvable Lie algebra of derived length 2 with non-singular derivation. By Proposition \ref{prop:cocic}, there is a cocycle $\vartheta \in \ztwo K I$ such that $L \cong K_{\vartheta}$. This calculation show us that every Lie algebra that answer Problem 1 can be obtained by an extension of a solvable Lie algebra of derived length 2 with non-singular derivation. So we need to understand this Lie algebras of derived length 2 to search for an answer of Problem 1. We will study a variation of this question.
  
\textbf{Problem 2.} Let $K$ be one of the known solvable, non-nilpotent Lie algebra over a field of characteristic $p\geq 3$ with non-singular derivation and derived length 2. Is there a non-trivial $K$-module $I$ and a cocycle $\vartheta \in \ztwo K I$ such that $K_\vartheta$ has a non-singular derivation? 

As first step to study Problem 2 we will try to describe some cases of abelian Lie algebras $K$ acting over vector spaces. This study defines our next objectives in this project.
 
\textbf{Objectives}
 
\begin{itemize} 
\item To characterize solvable non-nilpotent modular Lie algebras of the form $L=\langle x \rangle \sdsum I$ where $I$ is a finite dimensional abelian Lie algebra  such that $L$ admits a non-singular derivation; study the extensions of such algebras and obtain ones that admits non-singular derivations; By Corollary \ref{teo1.8cor}, there is a quotient $Q=L^{(i)}/L^{i+1}$ with $\dim Q \geq p$. Study the number of such quotients.
    
\item How the existence of non-singular derivations affect the structure of $\der L$? Can we define some algebra structure over non-singular derivations of $L$? 
\item Stydy the general structure of solvable non-nilpotent Lie algebras with non-singular derivations
\end{itemize}  

 
\section{Derivations and Lie algebra extensions}{\label{extensions}}

\subsection{Lie algebra extensions}

An {\em extension} of a Lie algebra  $K$ by a Lie algebra
$I$  is an exact sequence 
\begin{equation}\label{ext}
0 \to I \stackrel{ i}{\to} L \stackrel{ s}{\to} K \to 0
\end{equation}
of Lie algebras.
The Lie algebra $L$ in the middle of the exact sequence contains an
ideal
$\ker s=\mbox{Im}\,i\cong I$ such that $L/I\cong K$. We will write
informally that
`$L$ is an extension of $K$ by $I$'. The extension~\eqref{ext}
{\em splits}
if $L$ has a subalgebra $S$ such that $L=S \dotplus\ker s$. 
The extension~\eqref{ext} is {\em trivial} if there exists an ideal $S$ of $L$
such that $L=S\oplus\ker s$. The extension~\eqref{ext} is central if 
$\ker s$ lies in the center $Z(L)$ of $L$.

Let $K$ be a Lie algebra over a field $\F$
and let $I$ be a vector space over $\F$.
Denote by $\ctwo KI$ the vector space of alternating bilinear maps
$\vartheta: K \times K \to I$.
If $I$ is a $K$-module and
$\vartheta \in \ctwo KI$ has the property that
\begin{equation}{\label{cocdef}}
\vartheta(x,[y,z])+\vartheta(y,[z,x])+\vartheta(z,[x,y])+
[x,\vartheta(y,z)]+[y,\vartheta(z,x)]+[z,\vartheta(x,y)]=0,
\end{equation}
for all $ x,\ y,\ z \in K$, then $\vartheta$ is said to be a
{\em cocycle} and the vector space of coclycles is denoted by $\ztwo KI$.
Let $T:K \to I$ be a linear transformation and define, 
$\vartheta_T:K\times K\rightarrow I$ by
\begin{equation}{\label{cobdef}}
\vartheta_T(h,k)=T([h,k])+[k,T(h)]-[h,T(k)]\quad
\mbox{for all}\quad h,\ k \in K.
\end{equation}
Then $\vartheta_T\in\ztwo KI$ and such a cocycle $\vartheta_T$ is said to be
a {\em coboundary}.
The set of coboundaries is denoted by $\btwo KI$. 
The set $\btwo KI$ is a subspace of
$\ztwo KI$, and we set $\htwo KI=\ztwo KI/\btwo KI$ to be
the quotient space. 
The first cohomology group of $K$ and $I$ is defined as
$$\zone KI=\{\nu \in \hom KI \mid \nu([h,k])=[h,\nu(k)]-[k,\nu(h)]
\mbox{ for all } h,\ k \in K\}.
$$

The next result, whose proof can be found, for instance, 
in \cite[Section~4.2]{Knapp}, links Lie algebra extensions to cohomology.
Let $K$ be a Lie algebra and let $I$ be a $K$-module.
  Let $\vartheta \in \ztwo KI$ and
  define the Lie algebra $K_{\vartheta}=K \dotplus I$ with the product
  \begin{equation}{\label{defprod}}
 [x+a,y+b]=[x,y]+\vartheta(x,y)+[a,y]-[b,x] \mbox{ for all } x,\ y \in K \mbox{ and } a,\ b \in I.
 \end{equation}
 
\begin{prop} \label{prop:cocic}
 The following hold for the Lie algebra $K_\vartheta$:
 \begin{enumerate}
 \item $K_\vartheta$ is a Lie algebra extension of $K$ by $I$;
 \item if $\nu\in\btwo KI$, then
   $K_\vartheta$ is isomorphic to $K_{\vartheta+\nu}$;
 \item  if $\vartheta\in\btwo KI$, then
   $K_\vartheta$ is a split extension of $K$ by $I$.
 \end{enumerate}
 Conversely, let  $L$ be a Lie algebra and $J$ be an abelian ideal of
 $L$. Then there exists $\vartheta \in \ztwo{L/J}J$ such that
 $L \cong (L/J)_\vartheta$. 
\end{prop}

The cocycle $\vartheta$ in last the statement   of
Proposition~\ref{prop:cocic} can
be constructed as follows. Let $\pi:L\rightarrow L/I$ denote the
natural projection, and let $\sigma: L/I\rightarrow L$ be
a right inverse of $\pi$; that is,
$\pi\sigma=\mbox{id}_{L/I}$. Then, for $k+I,\ h+I\in L/I$,
set
$$
\vartheta(h+I,k+I)=\sigma([h+I,k+I])-[\sigma(h+I),\sigma(k+I)].
$$
Routine calculation shows that $\vartheta\in\ztwo {L/I}I$ and
that $L\cong L_\vartheta$.

 
\subsection{Compatible pairs and derivations of semidirect sums}

Compatible pairs were introduced in~\cite{Eick} to compute automorphisms
of solvable groups and solvable Lie algebras. We adopt the
concept for derivations of Lie algebras.  
Let $K$ and $I$ be Lie algebras such that $K$ acts on $I$
via the homomorphism $\psi:K\rightarrow\der I$.
We  define the {\em semidirect sum} $K\sdsum_\psi I$
as the vector
space $K\dotplus I$ with the product operation given as
$$
[(k_1,a_1),(k_2,a_2)]=([k_1,k_2],[k_1,a_2]-[k_2,a_1]+[a_1,a_2]).
$$
When the $K$-action on $I$ is clear from the context, then we
usually suppress the homomorphism `$\psi$' from the notation and write
simply $K\sdsum I$. If $L$ is a Lie algebra such that $L$ has
an ideal $I$ and a subalgebra $K$ in such a way that
$L=K\dotplus I$, then $L\cong K\sdsum_\psi I$ where $\psi$
is the restriction of $\ad {}I$ to $K$.
In a semidirect sum $K\sdsum I$, an element $(k,a)\in K\dotplus I$
will usually be written as $k+a$. 


Suppose that $K$ and $I$ are as in the previous paragraph.
The direct sum $\der K\oplus\der I$ of
the derivation Lie algebras is a Lie algebra.
An element $(\alpha,\beta)\in \der K\oplus\der I$ is said to be a
{\em compatible pair} if
\begin{equation}{\label{compeq}}
  \beta ([k,a])=[\alpha(k),a]+[k,\beta(a)] \quad\mbox{for all}\quad
  k \in K,\ a \in I.
\end{equation}
We let $\comp KI$ denote the set of compatible pairs in
$\der K\oplus\der I$.
Using the homomorphism $\psi:K\rightarrow\der I$
associated to the $K$-action on $I$, we can write equation (\ref{compeq}) in another form
as follows. 
Writing $[k,a]$ as $\psi(k)(a)$, we have that
$(\alpha,\beta) \in \comp KI$ if and only if the equation
\begin{equation*}
  \beta \psi(k)= \psi (\alpha(k))+\psi(k)\beta.
\end{equation*}
holds in $\der I$ for all  $k \in K$.
Using commutator, this is equivalent to  
\begin{equation}{\label{compcomu}}
  [\beta,\psi(k)]=\psi (\alpha(k)) \mbox\quad \mbox{for all} \quad k \in K.
\end{equation}
Letting $\ad{}{}:\der I\to \der I$ denote the 
adjoint representation, equation~\eqref{compcomu} can be rewritten
as
\begin{equation}{\label{compcomu2}}
\ad{}{\beta}\psi(k)=\psi (\alpha(k))\quad \mbox{for all}\quad k \in K.
\end{equation}
Therefore, $(\alpha,\beta) \in\comp KI$
if and only if the following diagram commutes:
$$ \xymatrix{K \ar[d]^{ \alpha} \ar[r]^{\psi} \ar@{}[dr]|{\circlearrowright} &
  {\der I} \ar[d]^{\ad{}{\beta}} \\ K \ar[r]^{\psi} & {\der I}.} $$

A compatible pair $(\alpha,\beta)\in
\der K\oplus\der I$ will usually be written as $\alpha+\beta$.
If $\alpha+\beta\in\der K\oplus\der I$ as above,
then $\alpha+\beta$ can be considered a element of
$\gl{I\oplus K}$ by letting $(\alpha+\beta)(k+a)=
\alpha(k)+\beta(a)$ for all $a\in I$ and $k\in K$.

\begin{prop}{\label{compsdsum}}
  Using the notation above,
  we have that
  $$
  \comp KI=\{\alpha+\beta\in\gl K\oplus\gl I\mid
  \alpha+\beta\in\der{K\sdsum I}\}.
  $$
  In particular $\comp KI$ is a Lie subalgebra of $\der{K\sdsum I}$.
\end{prop}
\begin{proof}

  Suppose that $\alpha+\beta\in\comp KI$ is a compatible pair
  and let $k+a,\ k'+a'\in K\sdsum I$.
  Then 
\begin{multline*}
  (\alpha+\beta)[k+a,k'+a'] =  (\alpha+\beta)
  ([k,k']+([k,a']-[k',a]+[a,a']))\\
  = \alpha([k,k'])+\beta([k,a']-[k',a]+[a,a'])\\
 =[\alpha(k),k']+[k,\alpha(k')]+[\alpha(k),a']-[\alpha(k'),a] \\ 
 +[\beta(a),a']+[k,\beta(a')]-[k',\beta(a)]+[a,\beta(a')].
  \end{multline*}
On the other hand
\begin{multline*}
[(\alpha+\beta)(k+a),k'+a']+[k+a,(\alpha+\beta)(k'+a')]=\\
[\alpha(k),k']+[\alpha(k),a']+[\beta(a),k']+[\beta(a),a']\\+
[k,\alpha(k')]+[k,\beta(a')]+[a,\alpha(k')]+[a,\beta(a')].
\end{multline*}
Thus $\alpha+\beta\in\der{K\sdsum I}$.

Conversely, let
$\alpha+\beta\in \gl{K}\oplus \gl I$ such that
$\alpha+\beta$ is a derivation of $K\sdsum I$. Then
$(\alpha+\beta)|_K=\alpha$ and $(\alpha+\beta)|_I=\beta$, and so
$\alpha\in\der K$ and $\beta\in\der I$. Further, if $k\in K$ and
$a\in I$, then $[k,a]\in I$, and so
$$
\beta([k,a])=(\alpha+\beta)[k,a]=[(\alpha+\beta)(k),a]+
     [k,(\alpha+\beta)(a)]=[\alpha(k),a]+[k,\beta(a)].
     $$
     Thus $\alpha+\beta\in\comp KI$, as required.

     The fact that $\comp KI$ is a Lie subalgebra of $\der{K\sdsum I}$
     follows from the fact that
     $\comp KI$ is the intersection of two Lie algebras; namely,
     $\comp KI=(\gl K\oplus\gl I)\cap\der{K\sdsum I}$.
\end{proof}


\begin{lem}{\label{comp^p}} Let $K$ and $I$ be Lie algebras over a field $\F$ of characteristic $p>0$. If $(\alpha,\beta) \in \comp KI$ then $(\alpha,\beta)^{p^t} \in \comp KI$ for all $t\geq 0$. 
\end{lem}
\begin{proof}
Let $L=K \sdsum I$ be the semi-direct sum of $K$ and $I$. By Proposition \ref{compsdsum}, $(\alpha,\beta) \in \der L$. Then by Lemma \ref{leib}, $(\alpha,\beta)^{p^t} \in \der L$, for all $t \geq 0$. Hence, by Proposition \ref{compsdsum}, $(\alpha,\beta)^{p^t} \in \comp K I$.
\end{proof}

Let $K$ and $I$ be vector spaces. Consider the Lie algebra
$\gl K\oplus\gl I$ and define an action of  $\gl K\oplus\gl I$
on the vector space $\hom K{\gl I}$ as follows.
Let $\ad{}{}$ denote the adjoint representation
of $\gl I$. Thus, for $\beta,\ \beta'\in\gl I$ and $\ad{}\beta(\beta')=
[\beta,\beta']$.
For $(\alpha,\beta) \in \gl K
\oplus \gl I$ and for $T \in \hom K{\gl I}$, set
 \begin{equation}{\label{acaocomp}}
 (\alpha,\beta)\cdot T=\ad{}{\beta}T-T\alpha.
 \end{equation}
 Let us show that this in fact defines a Lie algebra
 action.
 First notice that
 $(\alpha,\beta) \cdot T \in \hom K {\gl I}$ because it
 is linear combination of compositions of linear maps.
 Let us check that the action is compatible with Lie brackets.
 Let $(\alpha,\beta),\ (\alpha',\beta')
 \in \gl K \oplus \gl I$. By definition
 $$
 (\alpha',\beta')\cdot T=\ad{}{\beta'}T-T\alpha'.
 $$
 Thus
 $$(\alpha,\beta)\cdot((\alpha',\beta')\cdot T)=\ad{}{\beta}\ad{}{\beta'}T-\ad{}{\beta'}T\alpha-\ad{}{\beta}T \alpha'+T\alpha'\alpha.$$
 In the same way, 
$$(\alpha',\beta')\cdot((\alpha,\beta)\cdot T)=\ad{}{\beta'}\ad{}{\beta}T-\ad{}{\beta}T\alpha'-\ad{}{\beta'}T \alpha+T\alpha\alpha'.$$
Hence, $$\begin{array}{rcl}
(\alpha,\beta)\cdot((\alpha',\beta')\cdot T)-(\alpha',\beta')\cdot((\alpha,\beta)\cdot T) & = &\ad{}{\beta}\ad{}{\beta'}T-\ad{}{\beta'}\ad{}{\beta}T-T\alpha\alpha'+T\alpha'\alpha \\ 
&=& [\ad{}{\beta},\ad{}{\beta'}]T-T[\alpha,\alpha'].
\end{array}$$
Therefore, $$[(\alpha,\beta),(\alpha',\beta')]\cdot T= ([\alpha,\alpha'],[\beta,\beta'])\cdot T.$$

Now, if $K$ and $I$ are Lie algebras and $I$ is a $K$-module, then
there is a corresponding homomorphism
$\psi\in\hom K{\der I}$. Now suppose that $\alpha+\beta\in \gl K\oplus
\gl I$ such that $\alpha+\beta\in\der K\oplus\der I$. 
Then, for $k \in K$, we have $\ad{}{\beta}T(k)+T\alpha(k)$ is a derivation of $I$ since $\ad{}{\beta}T(k),\ T\alpha(k) \in\der I$.

If $X$ is a subalgebra of $\der K\oplus\der I$, then 
the annihilator $\ann X\psi$ of $\psi$ in $X$ is defined as
$$
\ann X\psi=\{(\alpha,\beta)\in X\mid
(\alpha,\beta)\cdot \psi=0\}.
$$
Computing the annihilator of $\psi$ in $\der K\oplus \der I$
explicitly, we obtain
\begin{multline*}
\ann{\der K\oplus \der I}\psi  =  \{(\alpha,\beta) \in \der K\oplus \der I \mid (\alpha,\beta)\cdot \psi=0 \} \\
= \{(\alpha,\beta) \in \der K\oplus \der I \mid  \ad{}{\beta}\psi-\psi\alpha=0 \} 
= \comp KI.
\end{multline*}
The last equality follows from~\eqref{compcomu2}.
Hence we have  proved the following  proposition.

\begin{prop} Let $K$ and $I$ be Lie algebras such that $I$
  is also a $K$-module via 
  the representation
  $\psi\in\hom K{\der I}$. Then
  $\comp KI=\ann{\der K\oplus\der I} \psi$, where the
  action of $\der K\oplus \der I$ on  $\hom K{\der I}$
  is given by~\eqref{acaocomp}.
\end{prop}


\subsection{Derivations of $K_\vartheta$}
 
 In this section we present a method to describe the derivations of an extension $K_\vartheta$ presented in Proposition \ref{prop:cocic}  from the derivations of the Lie algebra $K$. By an adaptation of the process used by Eick in \cite{Eick}, we set conditions which guarantee that a derivation of $K$ can be lifted to a derivation of $K_\vartheta$. 
  It is first necessary to define an action of $\gl K \oplus \gl I$ on the vector space of alternating bilinear maps.
  
   Let $K$ and $I$ be vector spaces. Let $(\alpha,\beta)$ be an element of the Lie algebra $\gl K \oplus \gl I$ and $\vartheta \in \ctwo K I.$ Define an action of $\gl K \oplus \gl I$ on $\ctwo K I$ by setting for $\vartheta \in \ctwo K I$
 \begin{equation}{\label{1}}
 (\alpha,\beta)\cdot \vartheta(h,k)=\beta(\vartheta(h,k))-\vartheta(\alpha(h),k)-\vartheta(h,\alpha(k)), \quad \mbox{ for all } h,k \in K.
 \end{equation}
  Let  $(\alpha',\beta') \in \gl K \oplus \gl I$, then 
    \begin{multline}{\label{5}}
 (\alpha,\beta)\cdot ((\alpha',\beta')\cdot \vartheta(h,k))= (\alpha,\beta)\cdot (\beta'(\vartheta(h,k))-\vartheta(\alpha'(h),k)-\vartheta(h,\alpha'(k))). 
 \end{multline} 
 
 Applying the action in each summand of the right-hand of equation (\ref{5}) we have
 
    $$(\alpha,\beta)\cdot \beta'(\vartheta(h,k)= \beta\beta'\vartheta(h,k))-\beta'\vartheta(\alpha(h),k)-\beta'\vartheta(h,\alpha(k)),$$
 
    $$(\alpha,\beta)\cdot \vartheta(\alpha'(h),k)= \beta\vartheta(\alpha'(h),k))-\vartheta(\alpha'\alpha(h),k)-\vartheta(\alpha'(h),\alpha(k)),$$
     
       $$(\alpha,\beta)\cdot \vartheta(h,\alpha'(k))= \beta\vartheta(h,\alpha'(k))-\vartheta(\alpha(h),\alpha'(k))-\vartheta(h,\alpha'\alpha(k)).$$ 
 
 Then 
\begin{multline*} 
 (\alpha,\beta)\cdot ((\alpha',\beta')\cdot \vartheta(h,k))= \beta\beta'\vartheta(h,k))-\beta'\vartheta(\alpha(h),k)-\beta'\vartheta(h,\alpha(k))  \\ -\beta\vartheta(\alpha'(h),k))+\vartheta(\alpha'\alpha(h),k)+\vartheta(\alpha'(h),\alpha(k)) \\ 
 -\beta\vartheta(h,\alpha'(k))+\vartheta(\alpha(h),\alpha'(k))+\vartheta(h,\alpha'\alpha(k)).
 \end{multline*}
It follows 
\begin{eqnarray*}
[(\alpha,\beta),(\alpha',\beta')]\cdot \vartheta(h,k) & = &[\beta,\beta']\vartheta(h,k)-\vartheta([\alpha,\alpha'](h),k)-\vartheta(h,[\alpha,\alpha'](k)) \\
 & = & ([\alpha,\alpha'],[\beta,\beta']) \cdot \vartheta(h,k).
\end{eqnarray*}
 Therefore, the action presented in (\ref{1}) is well defined. 

Our goal now is to study the action of compatible pairs $\comp K I$ on subspaces $\ztwo K I$ and $\btwo K I$ of $\ctwo K I$. For this, assume that $K$ is a Lie algebra and $I$ is a $K$-module. Then for all $h,k,l \in K$, $(\alpha,\beta) \in \comp K I$ and $\vartheta \in Z^2(K,I)$ we have 
$$\begin{array}{rcl}
(\alpha,\beta)\cdot \vartheta(k,[h,l])& = &\beta(\vartheta(k,[h,l]))-\vartheta(\alpha(k),[h,l])-\vartheta(k,\alpha([h,l]))\\ 
& = & \beta(\vartheta(k,[h,l]))-\vartheta(\alpha(k),[h,l])-\vartheta(k,[\alpha(h),l])-\vartheta(k,[h,\alpha(l)]).
\end{array}$$ If $$X=(\alpha,\beta)\cdot\vartheta(k,[h,l])+(\alpha,\beta) \cdot \vartheta(h,[l,k])+(\alpha,\beta)\cdot\vartheta(l,[k,h]),$$ then
\begin{multline*} X=\beta(\vartheta(k,[h,l]))+\beta(\vartheta(h,[l,k]))+\beta(\vartheta(l,[k,h])) \\
 -\vartheta(\alpha(k),[h,l])-\vartheta(\alpha(h),[l,k])-\vartheta(\alpha(l),[k,h]) \\
-\vartheta(k,[\alpha(h),l])-\vartheta(h,[\alpha(l),k])-\vartheta(l,[\alpha(k),h]) \\
-\vartheta(k,[h,\alpha(l)])-\vartheta(h,[l,\alpha(k)])-\vartheta(l,[k,\alpha(h)]).\\
\end{multline*}
Using that $\beta$ is linear and the definition of cocycles (\ref{cocdef})
\begin{multline*}
X=-\beta([k,\vartheta(h,l)])-\beta([h,\vartheta(l,k)])-\beta([l,\vartheta(k,h)])\\
+[\alpha(k),\vartheta(h,l)]+[\alpha(h),\vartheta(l,k)]+[\alpha(l),\vartheta(k,h)]\\
+[k,\vartheta(\alpha(h),l)]+[h,\vartheta(\alpha(l),k)]+[l,\vartheta(\alpha(k),h)]\\
+[k,\vartheta(h,\alpha(l))]+[h,\vartheta(l,\alpha(k))]+[l,\vartheta(k,\alpha(h))].\\
\end{multline*}
Since $(\alpha,\beta)$ is a compatible pair we have by (\ref{compeq})

$$\beta([k,\vartheta(h,l)]) = [\alpha(k),\vartheta(h,l)]+ [k,\beta(\vartheta(h,l))];$$
$$\beta([h,\vartheta(l,k)]) = [\alpha(h),\vartheta(l,k)]+ [h,\beta(\vartheta(l,k))];$$
$$\beta([l,\vartheta(k,h)]) = [\alpha(l),\vartheta(k,h)]+ [l,\beta(\vartheta(k,h))].$$

Hence we obtain combining the last two displayed systems of equations
\begin{multline*}
X=-[k,\beta(\vartheta(h,l))]-[h,\beta(\vartheta(l,k))]-[l,\beta(\vartheta(k,h))]\\
+[k,\vartheta(\alpha(h),l)]+[h,\vartheta(\alpha(l),k)]+[l,\vartheta(\alpha(k),h)]\\
+[k,\vartheta(h,\alpha(l))]+[h,\vartheta(l,\alpha(k))]+[l,\vartheta(k,\alpha(h))].\\
\end{multline*} 
Again, by the definition of the action in (\ref{1})
$$X=-[k,(\alpha,\beta)\cdot\vartheta(h,l)]-[h,(\alpha,\beta)\cdot\vartheta(l,k)]-[l,(\alpha,\beta)\cdot\vartheta(k,h)].$$
 So $(\alpha,\beta)\cdot\vartheta \in \ztwo K I$.
 
 Now suppose that $\vartheta \in \btwo K I$. By definition (\ref{cobdef}) there is a linear map $T:K \to I$ such that $\vartheta=\vartheta_T$. Hence
 \begin{equation}
 {\label{1.4}} \vartheta_T(h,k)= T([h,k])+[k,T(h)]-[h,T(k)].
 \end{equation}
Let $Y=(\alpha,\beta)\cdot \vartheta_T(h,k)$. By (\ref{1.4}) we have 
 \begin{equation}{\label{1.7}}
  Y=\beta(\vartheta_T(h,k))-\vartheta_T(\alpha(h),k)-\vartheta_T(h,\alpha(k)).
\end{equation}
  Using the definition of $\vartheta_T$ we have
 \begin{eqnarray}{\label{1.9}}
 \beta(\vartheta_T(h,k)) & = &\beta T([h,k])+\beta [k,T(h)] - \beta [h,T(k)], \\
 \vartheta_T(\alpha(h),k) & = & T([\alpha(h),k])+[k,T \alpha(h)]-[\alpha(h),T(k)], \nonumber \\
 \vartheta_T(h,\alpha(k)) & = &T([h,\alpha(k)])+[\alpha(k),T(h)]-[h,T\alpha(k)]. \nonumber
  \end{eqnarray}
 We can use that $(\alpha,\beta)$ is a compatible pair in equation (\ref{1.9}) to write
 $$\beta(\vartheta_T(h,k))=\beta T([h,k])+ [\alpha(k),T(h)] +[k,\beta T(h)]-[\alpha(h), T(k)] -[h,\beta T(k)].$$
 Then
\begin{multline*}
Y=\beta T([h,k])+ [\alpha(k),T(h)] +[k,\beta T(h)]-[\alpha(h), T(k)] -[h,\beta T(k)]\\
-T([\alpha(h),k])-[k,T \alpha(h)]+[\alpha(h),T(k)]\\
-T([h,\alpha(k)])-[\alpha(k),T(h)]+[h,T\alpha(k)].\\
\end{multline*}
Making the cancellations, $Y$ can be written as  
\begin{multline*}
Y=\beta T([h,k])-T([\alpha(h),k])-T([h,\alpha(k)]) \\
+ [k,\beta T(h)]-[k,T \alpha(h)]+[h,T\alpha(k)]-[h,\beta T(k)].
\end{multline*}
Now we use that $T$ and the action are linear to obtain
\begin{multline*}
Y=\beta T([h,k])-T([\alpha(h),k]+[h,\alpha(k)])+[k,\beta T(h)-T \alpha(h)]-[h,\beta T(k)-T \alpha(k)].
\end{multline*}
 Hence, $$Y=(\beta T-T \alpha)([h,k])+[k,(\beta T-T \alpha)(h)]-[h,(\beta T-T \alpha)(k)].$$
 If $U=\beta T-T \alpha:K \to I$ then $$(\alpha,\beta)\cdot \vartheta(h,k)=U([h,k])-[k,U(h)]-[h,U(k)].$$ Therefore,  $(\alpha,\beta)\cdot\vartheta \in \btwo K I$. We just proof
   
\begin{prop}{\label{inva}} Let $K$ be a Lie algebra and let $I$ be a $K$-module. Consider the action of $\comp K I$ on $\ctwo K I$ defined in ({\ref{1}}). Then the vector spaces $\ztwo K I$ and $\btwo K I$ are invariants by this action.
\end{prop}

 This result allows us to define an action of $\comp K I$ on $\htwo KI$: let $\vartheta \in \ztwo KI$ and $(\alpha, \beta) \in \comp K I$. Define the action \begin{equation}{\label{acaoind}}
  (\alpha,\beta)\cdot (\vartheta +\btwo K I)=((\alpha,\beta)\cdot \vartheta)+\btwo K I.
 \end{equation}
 This is well defined by Proposition \ref{inva}.
 
  \begin{df}{\label{defind}}  Let $K$ be a Lie algebra and $I$ a $K$-module. Let $\vartheta \in \ztwo KI$ and consider the action of $\comp K I$ on $\htwo KI$ defined in (\ref{acaoind}). Define the set of induced pairs of $\comp K I$ by  $$\indu K I \vartheta={\sf Ann}_{\comp K I}(\vartheta+\btwo K I).$$
 \end{df}

\vspace{0,5cm}

Now we have the tools needed to describe the Lie algebra $\der {K_\vartheta}$ from the Lie algebra $\der K $. We will define a homomorphism $\phi : \der {  K_\vartheta} \to \der K$, whose kernel is known and the image coincides with the induced pairs defined above. So, using the First Isomorphism Theorem for Lie algebras we have $\der {  K_\vartheta}$ is isomorphic to $\ker \phi \oplus \im \phi$ but these subspaces correspond to structures: $\ker \phi \cong \sf Z^1 (K,I)$ and $\im \phi \cong \sf Indu (K,I, \vartheta)$. One application of this type of construction is using known information about the algebra $\der K$ to obtain information about the algebra $\der {K_\vartheta}$ as the existence of non-singular derivations. Therefore, this method will allow us to study some properties of Lie algebra extensions by cocycles. First we define $\phi$.


Let $K$ be a Lie algebra and $I$ a $K$-module. Let $\vartheta \in \htwo KI$ and $d \in \der {K_{\vartheta}}$. Suppose  that $I$, as ideal of $K_\vartheta$, it is invariant under $d$. Recall that $K_{\vartheta}= K \sdsum I$ and let $\pi_K:K_\vartheta\to K$ and $\pi_I:K_\vartheta\to I$ to be the natural vector space projections of $K_\vartheta$ onto $K$ and $K_\vartheta$ onto $I$. Then define the maps
\begin{itemize}{\label{w}}
\item $\alpha:K \to K$ by $\alpha(h)=\pi_K d(h)$, for all $h \in K$;
\item $\beta:I \to I$ by $\beta(a)=d(a),$ for all $a \in I$;
\item $\eta:K \to I$ by $\eta(h)=\pi_I d(h),$ for all $h \in K$.
\end{itemize} For each $h+a \in K_\vartheta$ we have   
\begin{equation}{\label{3}}
d(h+a)=\alpha(h)+\eta(h)+\beta(a) \mbox{ for all }h \in K  \mbox{ and } a \in I .
\end{equation}   

We can see that $\beta$ is a derivation of $I$ because it is restriction of $d$ to $I$. To see that $\alpha \in \der K$ let $x,y \in K$. To make our calculation more clear, we will denote $[\cdot,\cdot]_K$ the product in $K$, and by $[\cdot,\cdot]_\vartheta$ the product in $K_\vartheta.$
 Then by product definition on $K_\vartheta$  
 $$d([h,k]_\vartheta)=d([h,k]_K+\vartheta(h,k)).$$
  By the decomposition showed in (\ref{3})
   \begin{equation}{\label{1.3}}
  d([h,k]_\vartheta)=\alpha([h,k]_K)+\eta([h,k]_K)+\beta(\vartheta(h,k)).\end{equation} 
 We can calculate\begin{equation}\label{1.5}
 [d(h),k]_\vartheta+[h,d(k)]_\vartheta=[\alpha(h)+\eta(h),k]_\vartheta+[h,\alpha(k)+\eta(k)]_\vartheta, 
 \end{equation} and use the definition of the product in equation (\ref{1.5}) to get \begin{multline}{\label{1.6}}
 [d(h),k]_\vartheta+[h,d(k)]_\vartheta=[\alpha(h),k]_K+\vartheta(\alpha(h),k)-[k,\eta(h)]_\vartheta\\
 +[h,\alpha(k)]_K +\vartheta(h,\alpha(k))+[h,\eta(k)]_\vartheta.
\end{multline}
 Comparing the components of $K$ in (\ref{1.3}) and (\ref{1.6}) we have $$\alpha([h,k]_K)=[\alpha(h),k]_K+[h,\alpha(k)]_K,$$ and $\alpha \in \der K$. 

Now it is possible define our homomorphism $\phi$. Let $K$ be a Lie algebra and $I$ a $K$-module. Let $\vartheta \in \htwo KI$ and suppose  that $I$, as an ideal of $K_\vartheta$, is invariant under derivations. For all $x+a \in  K_{\vartheta}$ and $ d \in \der K_{\vartheta}$  write $d(h+a)=\alpha(h)+\eta(h)+\beta(a)$ with $\alpha \in \der K$ and $\beta \in \der I$. Then define $\phi:\der{K_\vartheta} \to \der K \oplus \der I$ by \begin{equation}{\label{defphi2}}
\phi(d)=(\alpha,\beta).
\end{equation}
 
The following calculation will check that $\phi$ is a Lie algebra morphism. Let $d,d' \in \der {K_\vartheta}$ such that  
$$ \begin{array}{rcl}
d(h+a) & = & \alpha(h)+ \eta(h)+\beta(a) \\
d'(h+a) & = & \alpha'(h)+ \eta'(h)+\beta'(a) ,
\end{array}$$ Then
$$\begin{array}{rcl}
 dd'(h)   & = & d(\alpha'(h)+ \eta'(h)+\beta'(a)) \\
           & = & \alpha \alpha'(h)+\eta(\alpha'(h))+\beta (\eta'(h)+\beta'(a)). \\
\end{array}$$ 
Hence, $\pi_K dd'(h)=\alpha \alpha'(h).$ Analogously, $\pi_K d'd(h)=\alpha' \alpha(h).$ 
So $\pi_K [d,d']=[\alpha,\alpha']$. As $\beta$ and $\beta'$ are defined by restriction of $d$ and $d'$ to $I$, respectively, then $\pi_I[d,d']=[\beta,\beta']$. Therefore,
$$ \phi([d,d'])=([\alpha,\alpha'],[\beta, \beta'])=[(\alpha,\beta),(\alpha',\beta')]=[\phi(d),\phi(d')],$$
and $\phi$ is indeed a Lie algebra homomorphism. 

The next result presents the first connection between compatible pairs and the homomorphism $\phi$. 

\begin{lem}{\label{comp<im}} Let $K$ be a Lie algebra and $I$ a $K$-module. Let $\vartheta \in \htwo KI$ and suppose  that $I$, as an ideal of $K_\vartheta$, is invariant under derivations. Let $\phi:\der{K_\vartheta} \to \der{K}\oplus \der{I}$ given by $\phi(d)=(\alpha,\beta)$, defined in {\eqref{defphi2}}. Then $\im \phi\leq \comp K I.$
\end{lem}
\begin{proof} Let $(\alpha,\beta) \in  \im \phi$. Then there is $d \in \der{K_\vartheta}$ such that $\phi(d)=(\alpha,\beta)$. If $h \in K$ and $a \in I$ then 
$$\begin{array}{rclc}
\beta([h,a]_\vartheta)  &= &  d([h,a]_\vartheta) & (\mbox{since }[h,a] \in I)\\
&&& \\
&= &  [d(h),a]_\vartheta+[h,d(a)]_\vartheta &( d \in \der {K_\vartheta})\\
&&& \\
&= &  [\alpha(h)+\eta(h),a]_\vartheta+[h,\beta(a)]_\vartheta & \\
&&& \\
&= &  [\alpha(h),a]_\vartheta+[h,\beta(a)]_\vartheta & (\mbox{since $I$ is abelian}).\\
\end{array}$$
\end{proof}

Now we present the main theorem of this section. Recall that for a Lie algebra $K$, for a $K$-module $I$, and for $\vartheta \in \ztwo K I$, $\indu K I \vartheta$ was defined in Definition \ref{defind}. 
 \begin{teo}{\label{DerExt}} Let $K$ be a Lie algebra and let $I$ be a $K$-module. Let $\vartheta \in \htwo KI$ and suppose  that $I$, as ideal of $K_\vartheta$, is invariant by derivations. Let $\phi:\der {K_\vartheta} \to \der K \oplus \der I$ be defined as above. Then:
 
 \begin{enumerate}
 \item $\im \phi= \indu K I \vartheta $
  \item $\ker \phi \cong \sf \zone KI$
  \end{enumerate}
\end{teo}
\begin{proof} In this proof we will denote the product in $K_\vartheta$ of $h \in K$ and $a \in I$ just by the action $[h,a]$ of $K$ on $I$, since $[h,a]_\vartheta=[h,a].$

 1) Let $(\alpha,\beta) \in \sf Indu(K,I,\vartheta)$. By definition  $$(\alpha,\beta)\cdot \vartheta=0  \mbox{ mod }  \btwo K I.$$ Then there is a linear map $T:K \to I$ such that, for all  $h,k \in K$,
 \begin{equation}{\label{2}}
  \beta(\vartheta(h,k))-\vartheta(\alpha(h),k)-\vartheta(h,\alpha(k))=T([h,k])+[k,T(h)]-[h,T(k)].
\end{equation}

 Let $h \in K$, $a \in I$ and define the linear map $(\alpha,\beta)^*:K_\vartheta  \to  K_\vartheta$ by 
 \begin{equation}{\label{deflift}}
 (\alpha,\beta)^*(h+a)=\alpha(h)-T(h)+\beta(a).
 \end{equation}
  Let's check that $(\alpha,\beta)^*$ is a derivation of $K_\vartheta$. Let $k+b \in K_\vartheta$. If $$X= (\alpha,\beta)^*([h+a,k+b]_\vartheta)$$ 
  then
   $$\begin{array}{rcl}
X & = & (\alpha,\beta)^*([h,k]_K+\vartheta(h,k)+[h,b]-[k,a])\\
& = & \alpha([h,k]_K)-T([h,k]_K)+\beta(\vartheta(h,k))+\beta([h,b])-\beta([k,a]).\\
\end{array}$$
Now, let $$Y=[(\alpha+\beta)^*(h+a),k+b]_\vartheta+[h+a,(\alpha+\beta)^*(k+b)]_\vartheta. $$
By definition \eqref{deflift}
$$ [(\alpha+\beta)^*(h+a),k+b]_\vartheta = [\alpha(h)-T(h)+\beta(a),k+b]_\vartheta.$$ 
Hence, by product definition in \eqref{defprod}
$$[\alpha(h)-T(h)+\beta(a),k+b]_\vartheta = [\alpha(h),k]_K+\vartheta(\alpha(h),k)+[\alpha(h),b]-[k,-T(h)+\beta(a)]$$ and 
$$[(\alpha+\beta)^*(h+a),k+b]_\vartheta = [\alpha(h),k]_K+\vartheta(\alpha(h),k)+[\alpha(h),b]-[k,-T(h)+\beta(a)].$$
 Analogously, 
 $$[h+a,(\alpha+\beta)^*(k+b)]_\vartheta = [h,\alpha(k)]_K+\vartheta(h,\alpha(h))+[h,-T(k)+\beta(b)]-[\alpha(k),a].$$ 
 It follows
 \begin{multline*}
 Y=[\alpha(h),k]_K+[h,\alpha(k)]_K+\vartheta(\alpha(h),k)+\vartheta(h,\alpha(h)) \\
+[\alpha(h),b]+[h,\beta(b)]-[k,\beta(a)]-[\alpha(k),a]-[h,T(k)]+[k,T(h)].
 \end{multline*}
We can use that $(\alpha,\beta) \in \comp K I$ to write $Y$ as 
\begin{multline*}
Y=\alpha([h,k]_K)+\vartheta(\alpha(h),k)+\vartheta(h,\alpha(h)) \\ +\beta([h,b])-\beta([k,a])-[h,T(k)]+[k,T(h)].
\end{multline*}
By equation ({\ref{2}}) 
$$\vartheta(\alpha(h),k)+\vartheta(h,\alpha(k))=\beta(\vartheta(h,k))-T([h,k])-[k,T(h)]+[h,T(k)].$$
Then
\begin{multline*}
$$ Y=[\alpha(h),k]_K+[h,\alpha(k)]_K+\beta(\vartheta(h,k))-T([h,k])-[k,T(h)]+[h,T(k)]\\ +\beta([h,b])-\beta([k,a])-[h,T(k)]+[k,T(h)].\end{multline*}

As $X=Y$ then $(\alpha,\beta)^*$ is a derivation.

 Besides, observe that $\pi_K(\alpha,\beta)^*=\alpha$ and $\pi_I(\alpha,\beta)^*=\beta$. Hence $\phi((\alpha+\beta)^*)=(\alpha,\beta)$, that is, $\indu K I\vartheta \subseteq \im \phi$. 
 
 Now, suppose that $(\alpha,\beta) \in \im \phi$. Then there is $d \in \der {K_\vartheta}$ such that $$\phi(d)=(\alpha,\beta).$$ By Theorem \ref{comp<im} we have $\im \phi \subseteq \comp K I$. Then it is enough to show that there is a linear map $T:K \to I$ such that the equation (\ref{2}) is satisfied.
 
  For each $h+a \in K_\vartheta$ we can use the decomposition defined in ({\ref{3}}) to write  $$d(h+a)=\alpha(h)+\eta(h)+\beta(a).$$ Then  
 $$ [d(h+a),k+b]_\vartheta  = [\alpha(h)+\eta(h)+\beta(a),k+b]_\vartheta. $$
By product definition in \eqref{defprod} we get     
 $$[\alpha(h)+\eta(h)+\beta(a),k+b]_\vartheta= [\alpha(h),k]_K+\vartheta(\alpha(h),k)+[\alpha(h),b]-[k,\eta(h)+\beta(a)].$$
 Hence 
  $$[d(h+a),k+b]_\vartheta=  [\alpha(h),k]_K+\vartheta(\alpha(h),k)+[\alpha(h),b]-[k,\eta(h)+\beta(a)].$$
  Analogously,
 $$ [h+a,d(k+b)]_\vartheta =  [h,\alpha(k)]_K+\vartheta(h,\alpha(k))+[h,\eta(k)+\beta(b)]-[\alpha(k),a].$$
 Therefore 
 \begin{multline}
   [d(h+a),k+b]_\vartheta+[h+a,d(k+b)]_\vartheta =  [\alpha(h),k]_K+[h,\alpha(k)]_K +\vartheta(\alpha(h),k)+\vartheta(h,\alpha(k))\\ +[\alpha(h),b]+[h,\beta(b)] -[\alpha(k),a]-[k,\beta(a)]-[k,\eta(h)]+[h,\eta(k)].
 \end{multline}
 We can use that $(\alpha,\beta) \in \comp KI$ in the last displayed equation to write
   \begin{multline*}
   [d(h+a),k+b]_\vartheta+[h+a,d(k+b)]_\vartheta =  \alpha([h,k]_K)+\vartheta(\alpha(h),k)+\vartheta(h,\alpha(k))\\+ \beta([h,b]) -\beta([k,a])-[k,\eta(h)]+[h,\eta(k)].
 \end{multline*}
 Now we will calculate $d([k+a,h+b]_\vartheta)$. By product definition
 $$ d([h+a,k+b]_\vartheta)  =  d([h,k]_K+\vartheta(h,k)+[h,b]-[k,a]).$$
 Hence $$d([h,k]_K+\vartheta(h,k)+[h,b]-[k,a])= \alpha([h,k]_K)+\eta([h,k]_K)+\beta(\vartheta(h,k))+\beta([h,b])-\beta([k,a]).$$ 
 As $d$ is a derivation then we have equality  $$d([h+a,k+b]_\vartheta)=[d(h+a),k+b]_\vartheta+[h+a,d(k+b)]_\vartheta.$$
 It follows 
  $$  \vartheta(\alpha(h),k)+\vartheta(h,\alpha(k))-[k,\eta(h)]+[h,\eta(k)]=\eta([h,k]_K)+\beta(\vartheta(h,k)).$$
  We can rearrange the last displayed equation to get  
    $$-(\eta([h,k]_K)+[k,\eta(h)]-[h,\eta(k)])=\beta(\vartheta(h,k))-\vartheta(\alpha(h),k)-\vartheta(h,\alpha(k)).$$
    
  Therefore $T=-\eta$ satisfies the equation (\ref{2}) e $\im \phi \subseteq \sf Indu(K,I,\vartheta).$
 \vspace{0,5cm}  

 2) Let $d \in \ker \phi$. The decomposition showed in (\ref{3}) provide us $$d(h)=\eta(h),h \in K.$$ Let $h,k \in K$. By definition of derivation \begin{equation}{\label{4}}
 d([h,k]_\vartheta)=[d(h),k]_\vartheta+[h,d(k)]_\vartheta.
\end{equation}
 We can use product definition in $K_\vartheta$ to write 
  $$d([h,k]_\vartheta)=d([h,k]_K+\vartheta(h,k)).$$  Since $d \in \ker \phi$ then $$d([h,k]_\vartheta)=\eta([h,k]_K).$$
 By other hand,  $$[d(h),k]_\vartheta+[h,d(k)]_\vartheta=[\eta(h),k]_\vartheta+[h,\eta(k)]_\vartheta.$$
  
 Then (\ref{4}) it is equal to $$\eta([k,h]_K)=[k,\eta(k)]-[h, \eta(k)],$$ and $\eta \in  \sf Z^1(K,I)$. Observe that $\eta$ is the restriction of $d$ to $K$. Denote the restriction of $d$ to $K$ by $d|_K$. Therefore, if $d \in \ker \phi$ then  $d|_K \in \zone KI$.
   
    Let $d \in \ker \phi$  and define $\sigma: \ker \phi \to (\zone KI,+)$ by $\sigma(d)=d|_K$. Then $\sigma( \ker \phi ) \subseteq \sf \zone KI$. Let $d' \in \ker \phi$. Then $$\sigma(d+d')=(d+d')|_K=d|_K+d'|_K =\sigma(d)+\sigma(d').$$  So $\sigma$ it is group homomorphism.
 
First we will show that $\sigma$ is injective. Let $d,d' \in \ker \phi$ such that $\sigma(d)=\sigma(d')$. Let $h+a \in K_\vartheta$. Then $$d(h+a)=d(h)=d|_K(h)=d'|_K(h)=d'(h)=d(h+a).$$ Hence $d=d'$. Now, to prove that $\sigma$ is onto, let $\eta \in \zone KI$ and define a linear map $d:K_\vartheta \to K_\vartheta$ by $$d(h+a)=T(x), h \in K, a \in I.$$ We will show that $d$ is a derivation. Observe that, for all $h+a,k+b \in K_\vartheta$ we have
$$ d([h+a,k+b]_\vartheta)=d([h,k]_K+\vartheta(h,k)+[h,b]-[k,a]) 
 =\eta([h,k]_K).$$
 By other hand, 
 \begin{multline*}
 [d(h+a),k+b]_\vartheta+[h+a,d(k+b)]_\vartheta=[\eta(h),k+b]_\vartheta+[h+a,\eta(k)]_\vartheta \\
 =-[k,\eta(h)]+[h,\eta(k)].\\
 \end{multline*}
 Since $\eta \in \zone KI$ then $d([h+a,k+b]_\vartheta)=[d(h+a),k+b]_\vartheta+[h+a,d(k+b)]_\vartheta,$ hence $d \in \der {K_\vartheta}$. It is immediate that $\phi(d)=0$. So $d \in \ker \phi$. As by definition, $\sigma(d)=\eta$ then $\sigma$ is onto and, therefore, is an isomorphism.
\end{proof}

\begin{ex}{\label{compex}} Let $L$ be a Lie algebra with an abelian ideal $I$ invariant by derivations. Set $K=L/I$. By Proposition \ref{prop:cocic}, there is a $\vartheta \in \ztwo K I$ such that $L \cong K_\vartheta$. Then we can apply the  map $\phi: \der {L} \to \der {L/I} \oplus \der I$ defined in Theorem \ref{DerExt}. Further, if $d \in \der {L}$ then $\phi(d)=(\alpha,\beta) \in \comp {L/I}{I}$. Hence, each derivation of $L$ gives rise to a pair of derivations $\alpha \in \der {L/I}$ and $\beta \in I$. In particular, if $d$ is non-singular then $\alpha$ and $\beta$ are non-singulars.
\end{ex}
 
 \subsection{Compatible pairs and Jacobson Theorem}{\label{secJacobson}} 
 
In this section we show some examples of the use of compatible pairs in the study of non-singular derivations.

 \begin{ex}{\label{0.7}} Let $K$ and $I$ be finite-dimensional Lie algebras over an algebraically closed field $\F$. Suppose that $K$ acts on $I$ by representation $\psi:K \to \der I$. Let $D \leq \comp K I $ be a subalgebra. Define $L= K \sdsum I$. By Proposition \ref{compsdsum}, $D \leq\der L $. If $D$ is nilpotent then $L$ has a decomposition into generalized eigenspaces of $D$. This decomposition induces decompositions in $K$ and $I$, since as $K$ and $I$ are invariants under $D$. Hence, $$L=K_{\lambda_1} \oplus \cdots \oplus K_{\lambda_r} \oplus I_{\mu_1}\cdots\oplus I_{\mu_s}.$$ In particular, we have $[K_{\lambda_i},I_{\mu_j}]\subseteq I_{\lambda_i+\mu_j}$ if $\lambda_i+\mu_j$ is eigenvalue of $D$ in $I$. Otherwise $[K_{\lambda_i},I_{\mu_j}]=0$.
\end{ex} 
From this example we can state a result:

\begin{prop} \label{0.6} Let $K$ and $I$ be finite-dimensional Lie algebras over an algebraically closed field $\F$. Suppose that $K$ acts on $I$ by representation $\psi:K \to \der I$. Let $D \leq \comp K I $ be a subalgebra.  Suppose that 0 is not generalized eigenvalue of $D$. Then if either the characteristic of $\F$ is zero or the characteristic of $\F$ is $p$ and $D$ has at most $p-1$ generalized eigenvalues, then the Lie subalgebra $\psi(K) \leq \gl I$ is nilpotent.
\end{prop}

\begin{proof} Let $L=K_{\lambda_1} \dotplus \cdots \dotplus K_{\lambda_r} \dotplus I_{\mu_1}\cdots\dotplus I_{\mu_s}$ the generalized eigenspace decomposition presented in Example \ref{0.7}. Suppose that 0 is not generalized eigenvalues of $D$. Let $E_K= \{ \lambda_1, \cdots, \lambda_r \}$ and $E_I=\{\mu_1, \cdots, \mu_s \}$ be the generalized eigenvalues  of $D$ in $K$ and $I$, respectively. Let $k \in K_{\alpha_j}, a \in I_{\mu_i}$ then
 
 $$\left\lbrace\begin{array}{ccl}
\psi^n(k)(a) \in I_{\mu_i+n\lambda_j} & if & \mu_i+n\lambda_j \in E_I \\ 
\psi^n(k)(a) =0  & if & \mu_i+n\lambda_j \notin E_I. \\ 
\end{array} \right.$$
\begin{itemize}
\item If the characteristic of $\F$ is 0 then the linear functions $\mu_i+ \lambda_j, \mu_i+2 \lambda_j, \cdots, \mu_i+n \lambda_j \cdots$ are all distinct since $\lambda_j \neq 0$. Since $\dim I$ is finite, so $\mu_i+n \lambda_j \notin E_I$ for some $n>0$. Hence $\psi(k)^n=0$.
\item  If the characteristic of $\F$ is $p>0$ and $s < p$ then the linear forms $\{\mu_i+ \lambda_j, \mu_i+2 \lambda_j, \cdots, \mu_i+(p-1)\lambda_j,\mu_i\}$ cannot be all non-trivial, and so $\mu_i+ n \lambda_j=0$ for some $1 \leq n \leq p$, and so $\psi^n(k)=0$ for some $n$, $1 \leq n \leq p$.
\end{itemize} 
 In both cases $\psi(k)$ is nilpotent for all $k \in K_{\lambda_j}$, $1 \leq j \leq r$. Let $S= \bigcup \psi(K_{\lambda_j})$. Since $S$ is a weakly closed set such that each element is nilpotent. Then the associative subalgebra $\langle S \rangle \leq \ennd I$ is nilpotent. We conclude that the Lie algebra $\langle S \rangle =\psi(K)\leq \gl I$ is nilpotent.
\end{proof}

  For our next example we need some result about traces of matrices.
 
\begin{prop}{\label{0.9}} Let $\F$ be a field of characteristic $p \geq 0$. Suppose that $A \in {\sf M}(n, \F)$ with $n<p$ or $p=0$. Then $A$ is nilpotent if, and only if, the trace of matrices $A^r$ is zero, for $1 \leq r \leq n$.
\end{prop}
\begin{proof} Let $\bar{\F}$ be the algebraic closure of $\F$ and assume without loss of generality that $A$ is in Jordan normal form. We will use that a matrix is nilpotent if, and only if, zero is the only eigenvalue of $A$. 

Hence $A$ is as a diagonal block matrix where each block is formed by grouping the Jordan blocks associated to same eigenvalue. Let $\lambda_1, \cdots,\lambda_k$ be the non-zero eigenvalues of $A$. Denote by $A_t$ the diagonal block in $A$ associated with eigenvalue $\lambda_t$ and let assume that $A_t$ is an $n_j \times n_j$-matrix. Then 
\begin{equation}{\label{1.0}}
tr(A^r)=n_1 \lambda_1^n+\cdots+n_k\lambda_k^n. 
\end{equation}

Suppose that $A$ is nilpotent. Then zero is the only eigenvalue of $A$, and also of $A^r$ for all $r \geq 1$, and by equation ({\ref{1.0}}) we have $tr(A^r)=0$ for $1 \leq r \leq n$.

 Conversely, suppose that $tr(A^r)=0$ for $1 \leq r \leq n$. From equation  ({\ref{1.0}}) we can extract the system 
  \begin{equation}{\label{0.8}}
n_1 \lambda_1^r+\cdots+n_k\lambda_k^r=0, \hspace{1cm} 1 \leq r \leq k,
\end{equation} 
of linear equations in the variables $n_1, \cdots, n_k$ over $\F$ considering each $n_j$ as the element $n_j \cdot 1$ in $\F$, whose matrix of coefficients is

$$C= \begin{bmatrix}
\lambda_1 & \lambda_2 & \cdots & \lambda_k \\
\lambda_1^2 & \lambda_2^2 & \cdots & \lambda_k^2 \\
\vdots & \vdots &\ddots & \vdots \\
\lambda_1^k & \lambda_2^k & \cdots & \lambda_k^k \\
\end{bmatrix}. $$ 
Denote by $m_i(\lambda)$ the operation that multiplies line $i$ of a matrix by $\lambda$ and $A^t$ the transposed matrix of $A$. So we can write $$C= m_1(\lambda_1).m_2(\lambda_2) \cdots m_k(\lambda_k).V^t,$$ where

$$V= \begin{bmatrix}
1 & \lambda_1 & \lambda_1^2 \cdots & \lambda_1^{k-1} \\
1 & \lambda_2 & \lambda_2^2 \cdots & \lambda_2^{k-1} \\
\vdots & \vdots& \vdots  & \vdots \\
1 & \lambda_k & \lambda_k^2 \cdots & \lambda_k^{k-1} \\

\end{bmatrix} $$ is the Vandermonde matrix in the variables $\lambda_1, \lambda_2, \cdots, \lambda_k$ whose determinant is $\det V=\prod_{1 \le i<j\le n}(\lambda_j-\lambda_i)$. As the $\lambda_i$ are pairwise distinct we have that $\det V$ is non-zero. Then the determinant of $C$ is $\lambda_1.\lambda_2 \cdots \lambda_k. \det V$. As we assume that $\lambda_i \neq 0$ for $1, \cdot, k$, $C$ is non-singular. It follows that the system (\ref{0.8}) has only trivial solution. Therefore, considered as an element of $\F$, each $n_j$ is zero. If $p=0$ then zero is the only eigenvector of $A$. If $p>0$, then, since we assume that $n<p$, we also have that $n_j<p$ for all $j$. Hence the fact that $n_j=0$ in $\F$, implies that $n_j=0$ as a natural number. Conclude that zero is the only eigenvalue of $A$.  
\end{proof}

\begin{prop}[\cite{Bernstein}, Fact 3.17.13]{\label{1.2}} Let $\F$ be a field of characteristic $p>0$. Let $A,B,C \in {\sf M}(n,\F)$ with $p=0$ or $n<p$. If $[A,B]=C+\lambda B$, for some $\lambda \in \F$ and $[B,C]=0$ then $[A,B^r]=rB^{r-1} C+\lambda r B^r$ for all $r \geq 1$. In particular, if $\lambda \neq 0$ and  $C$ is nilpotent then $B$ is nilpotent.
\end{prop}
\begin{proof} We prove this result by induction on $r$. The case $r=1$ follows from the conditions. Suppose that result is valid for $(r-1)$. Then, $$[A,B^{r-1}]=(r-1)B^{r-2}C+\lambda (r-1)B^{r-1}.$$ We can rewrite this equation as
 $$\lambda (r-1)B^{r-1} =  AB^{r-1}-B^{r-1}A -(r-1)B^{r-2}C.$$
 Multiplying the the last equation on the right by $B$ we have
 $$\lambda (r-1)B^r =  AB^r-B^{r-1}(AB) -(r-1)B^{r-2}(CB).$$
 By the conditions we can write $AB=BA+C +\lambda B$ and $CB=BC$. Replacing these terms above we obtain  
  $$\lambda (r-1)B^r = AB^r-B^rA -B^{r-1}C-\lambda B^r -(r-1)B^{r-1}C.$$
  Therefore,  $$AB^r-B^rA = \lambda r B^r +r B^{r-1}C .$$
  
For the second statement suppose $\lambda \neq 0$ and $C$ is nilpotent with nilpotency index $m$. Using the first assertion we have
$$B^r = (1/\lambda r)[A,B^r] -(1/\lambda)B^{r-1}C, \mbox{ for all } r \geq 1.$$
Since, $B$ and $C$ commute, $(B^{r-1}C)^m=(B^{r-1})^m(C)^m=0$, Hence, for all $r \geq 1$ $B^{r-1}C$ is nilpotent and has trace zero by Proposition {\ref{0.9}}. As the trace of commutators is always zero then $tr([A,B^r])=0$ for all $r \geq 1$. It follows that $tr(B^r)=0$ for all $r \geq 1$ and again by Proposition {\ref{0.9}} we conclude that $B$ is nilpotent.
\end{proof}

Now we can present a result similar to the Proposition \ref{0.6} but with a new proof using compatible pairs.

\begin{teo}{\label{1.8}} Let $K$ and $I$ be finite dimensional Lie algebras over a field of characteristic $p \geq 0$ such that $K$ is solvable. Suppose that $K$ acts on $I$ by representation $\psi:K \to \der I$. Let $(\alpha, \beta) \in \comp K I$ such that $\alpha$ has no eigenvalue 0. If either $p=0$ or $p>0$ and dimension of $I$ is less than $p$ then $Tr(\psi^n(k))=0$, for all $k \in K$. In these two cases, $\psi(k)$ is nilpotent for all $k \in K$. 
\end{teo}

\begin{proof} As $\alpha$ has no eigenvalue 0, it is non-singular. Suppose that the order of $\alpha$, considered as an endomorphism of $I$, is $p^tm$. Then by Lemma \ref{comp^p}, $(\alpha,\beta)^{p^t}=(\alpha^{p^t},\beta^{p^t})$ is a compatible pair and by Proposition \ref{NonSDiag}, $\alpha^{p^t}$ is diagonalizable. Hence by possibly replacing $(\alpha, \beta)$ by $(\alpha,\beta)^{p^t}$, we may assume without loss of generality that $\alpha$ is diagonalizable. Let $x_1,...,x_s$ be a basis of $K$ such that $\alpha(x_i)=\lambda_i x_i$. For all $a \in \gl I$ denote by $[a]$ the matrix of $a$ in this basis. Then, by equation \eqref{compcomu}, $$[[\beta],[\psi(x_i)]]=\lambda_i[\psi(x_i)].$$ We can apply Proposition {\ref{1.2}} to this last equation for $A=[\beta]$, $B=[\psi(x_{i})]$, $C=0$ and  $\lambda=\lambda_i \neq 0$ to conclude that $\psi(x_i)$ is nilpotent for $1 \leq i \leq s$. Now we observe that if $K$ is a nilpotent Lie algebra in either characteristic is 0 or characteristic $p$ with dimension of $L$ less than $p$ then Lie's Theorem (Theorem \ref{Lie}) is valid. Lie's Theorem grants that there is a basis of $I$ such that the image of $\psi$ lies in the subalgebra of $\gl I$ formed by upper triangular matrices. Since $[\psi(x_i)]$ is nilpotent and upper triangular, it must be strictly upper triangular (that is, it contains zeros in the diagonal). Then all $\psi(k)$, for all $k \in K$, are also strictly upper triangular matrices, since they are linear combinations of the $\psi(x_i)$. Hence every $\psi(k)$ is nilpotent.
\end{proof} 

\begin{cor}{\label{teo1.8cor}} Let $L$ be a solvable Lie algebra over a field $\F$ of characteristic $p\geq 0$. Suppose that $L$ has a nonsingular derivation. If either $p=0$ or $p>0$ and dimension of $L^{(i)}/L^{(i+1)} <p$, for all $i$, then $L$ is nilpotent.
\end{cor}

\begin{proof} Suppose that $L > L^{(1)} > \cdots > L^{(k)} > L^{(k+1)}=0 $ is the derived series of $L$. We prove this result by induction on $k$. When $k=0$, then $L$ is clearly nilpotent, as it is actually abelian. Suppose that the result holds for Lie algebras of derived length $k-1$ and assume that L has derived length $k.$ Then $I=L^{(k)}$ is an abelian ideal of L. Setting $K=L/I$, we have that $K$ acts on $I$ (see Example \ref{adjrepex}) and let us call the corresponding representation $\psi$.  Further, since the terms of the  derived series are invariant under derivations, a non-singular derivation $\delta \in \der L$ gives rise to a compatible pair $(\alpha,\beta) \in \comp KI$ as explained in Example \ref{compex}. Since $\delta$ is non-singular, so are $\alpha \in \der K$ and $\beta\in \der I$. Note that $K$ is solvable of solvable length $k-1$ and $K^{(i)}/K^{(i+1)} \cong L^{(i)}/L^{(i+1)}$ for all $i\leq k-1$. Hence the induction hypothesis is valid for $K$ and we obtain that $K$ is nilpotent. Further, since $\dim I<p$, we have that $\psi(k)$ is nilpotent for all $k$. Now Proposition \ref{adnilp} implies that $L$ is nilpotent.
\end{proof}
 
\newpage
\

\bibliographystyle{plain}
\bibliography{mybib}











\end{document}
